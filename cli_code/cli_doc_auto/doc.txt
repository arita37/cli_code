D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\data.py
----------------methods----------------

---------------functions---------------
get_dataset(data_pars,   )
import_data_dask(  **kw)
import_data_fromfile(  **kw)
import_data_tch( name="", mode="train", node_id=0, data_folder_root="",  )
os_package_root_path(filepath,  sublevel=0, path_add="",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\distri_torch.py
----------------methods----------------

---------------functions---------------
load_arguments(  )
metric_average(val, name,   )
test(  )
train(epoch,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\models.py
----------------methods----------------

---------------functions---------------
cli_load_arguments( config_file=None,  )
config_generate_json(modelname,  to_path="ztest/new_model/",  )
config_get_pars(config_file,  config_mode="test",  )
config_init( to_path=".",  )
config_model_list( folder=None,  )
fit(module, model,  sess=None, data_pars=None, compute_pars=None, out_pars=None,  **kwarg)
fit_metrics(module, model,  sess=None, data_pars=None, compute_pars=None, out_pars=None,  **kwarg)
get_params(module, params_pars,   **kwarg)
load(module, load_pars,   **kwarg)
main(  )
metrics(module, model,  sess=None, data_pars=None, compute_pars=None, out_pars=None,  **kwarg)
model_create(module,  model_pars=None, data_pars=None, compute_pars=None,  **kwarg)
module_env_build( model_uri="", verbose=0, env_build=0,  )
module_load( model_uri="", verbose=0, env_build=0,  )
module_load_full( model_uri="", model_pars=None, data_pars=None, compute_pars=None, choice=None,  **kwarg)
os_folder_copy(src, dst,   )
predict(module, model,  sess=None, data_pars=None, compute_pars=None, out_pars=None,  **kwarg)
save(module, model, session, save_pars,   **kwarg)
test(modelname,   )
test_all( folder=None,  )
test_api( model_uri="model_xxxx/yyyy.py", param_pars=None,  )
test_global(modelname,   )
test_module( model_uri="model_xxxx/yyyy.py", param_pars=None,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\optim.py
----------------methods----------------

---------------functions---------------
cli_load_arguments( config_file=None,  )
main(  )
optim( model_uri="model_tf.1_lstm.py", hypermodel_pars={}, model_pars={}, data_pars={}, compute_pars={}, out_pars={},  )
optim_optuna( model_uri="model_tf.1_lstm.py", hypermodel_pars={}, model_pars={}, data_pars={}, compute_pars={"method" : "normal/prune", 'ntrials': 2, "metric_target": "loss" }, out_pars={},  )
optim_skopt( model_uri="model_tf.1_lstm.py", hypermodel_pars={}, model_pars={}, data_pars={}, compute_pars={"method" : "normal/prune", 'ntrials': 2, "metric_target": "loss" }, out_pars={},  )
post_process_best(model, model_uri, model_pars_update, data_pars, compute_pars, out_pars,   )
test_all(  )
test_fast( ntrials=2,  )
test_json( path_json="", config_mode="test",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\pipeline.py
----------------methods----------------
Pipe.__init__(self, pipe_list, in_pars, out_pars,  compute_pars=None,  **kw)
Pipe.get_checkpoint(self,   )
Pipe.get_fitted_pipe_list(self,  key="",  )
Pipe.get_model_path(self,   )
Pipe.run(self,   )

---------------functions---------------
drop_cols(df,  cols=None,  **kw)
generate_data(df,  num_data=0, means=[], cov=[[1, 0],  )
get_params( choice="", data_path="dataset/", config_mode="test",  **kw)
load_model(path,   )
log( n=0, m=1,  *s)
os_package_root_path(filepath,  sublevel=0, path_add="",  )
pd_concat(df1, df2, colid1,   )
pd_na_values(df,  cols=None, default=0.0,  **kw)
pipe_checkpoint(df,   **kw)
pipe_load(df,   **in_pars)
pipe_merge(in_pars, out_pars,  compute_pars=None,  **kw)
pipe_run_inference(pipe_list, in_pars, out_pars,  compute_pars=None, checkpoint=True,  **kw)
pipe_split(in_pars, out_pars, compute_pars,   **kw)
save_model(model, path,   )
test( data_path="/dataset/", pars_choice="colnum",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\util.py
----------------methods----------------
Model_empty.__init__(self,  model_pars=None, data_pars=None, compute_pars=None,  )
to_namespace.__init__(self, adict,   )
to_namespace.get(self, key,   )

---------------functions---------------
env_build(model_uri, env_pars,   )
env_conda_build( env_pars=None,  )
env_pip_check( env_pars=None,  )
env_pip_requirement( env_pars=None,  )
get_model_uri(file,   )
get_pretrained_path(  )
get_recursive_files(folderPath,  ext='/*model*/*.py',  )
get_recursive_files2(folderPath, ext,   )
get_recursive_files3(folderPath, ext,   )
load(load_pars,   )
load_config(args, config_file, config_mode,  verbose=0,  )
load_gluon(load_pars,   )
load_keras(load_pars,   )
load_pkl(load_pars,   )
load_root_config(  )
load_tch(load_pars,   )
load_tch_checkpoint(model, optimiser, load_pars,   )
load_tf( load_pars="",  )
log( n=0, m=1,  *s)
model_get_list( folder=None, block_list=[],  )
os_file_current_path(  )
os_folder_copy(src, dst,   )
os_get_file( folder=None, block_list=[], pattern=r'*.py',  )
os_package_root_path( filepath="", sublevel=0, path_add="",  )
os_path_split(path,   )
params_json_load(path,  config_mode="test",  )
path_norm( path="",  )
save( model=None, session=None, save_pars=None,  )
save_gluon( model=None, session=None, save_pars=None,  )
save_keras( model=None, session=None, save_pars=None,  )
save_pkl( model=None, save_pars=None,  )
save_tch( model=None, optimizer=None, save_pars=None,  )
save_tch_checkpoint(model, optimiser, save_pars,   )
save_tf( model=None, sess=None, save_pars=None,  )
test_module( model_uri="model_tf/1_lstm.py", data_path="dataset/", pars_choice="json", reset=True,  )
tf_deprecation(  )
val(x, xdefault,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\ztest.py
----------------methods----------------

---------------functions---------------
cli_load_arguments( config_file=None,  )
main(  )
os_file_current_path(  )
test_all(  )
test_custom(  )
test_import(  )
test_list(mlist,   )
test_model_structure(  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\ztest_structure.py
----------------methods----------------

---------------functions---------------
code_check( sign_list=None, model_list=None,  )
find_in_list(x, llist,   )
get_recursive_files(folderPath,  ext='/*model*/*.py',  )
log( n=0, m=1,  *s)
main(  )
model_get_list( folder=None, block_list=[],  )
os_file_current_path(  )
os_package_root_path(filepath,  sublevel=0, path_add="",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\__init__.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_chatbot\__init__.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_chatbot\diag_gpt\Chatbot_run.py
----------------methods----------------

---------------functions---------------
generate(  )
get_bot_response(  )
home(  )
recalc( p=None,  )
reinput(user_msg,   )
top_p_filtering(logits,  top_p=0.9, filter_value=-float('Inf'),  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_chatbot\diag_gpt\myChatbot.py
----------------methods----------------

---------------functions---------------
generate(  )
get_bot_response(  )
home(  )
recalc( p=None,  )
reinput(user_msg,   )
top_p_filtering(logits,  top_p=0.9, filter_value=-float('Inf'),  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_dev\ml_mosaic.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_dev\mytest.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_dev\__init__.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_dev\dev\ml_mosaic.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_dev\dev\mytest.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_flow\mlflow_run.py
----------------methods----------------

---------------functions---------------
cli_load_arguments(  )
log_scalar(name, value, step,   )
mlflow_add(args,   )
session_init(args,   )
tfboard_add_weights(step,   )
tfboard_writer_create(  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_flow\__init__.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_flow\dev\mlflow_run.py
----------------methods----------------

---------------functions---------------
cli_load_arguments(  )
log_scalar(name, value, step,   )
mlflow_add(args,   )
session_init(args,   )
tfboard_add_weights(step,   )
tfboard_writer_create(  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_gluon\gluon_automl.py
----------------methods----------------
Model.__init__(self,  model_pars=None, compute_pars=None,  )

---------------functions---------------
_config_process(config,   )
get_params( choice="", data_path="dataset/", config_mode="test",  **kw)
path_setup( out_folder="", sublevel=0, data_path="dataset/",  )
test( data_path="dataset/", pars_choice="json",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_gluon\gluon_deepar.py
----------------methods----------------
Model.__init__(self,  model_pars=None, data_pars=None, compute_pars=None,  **kwargs)

---------------functions---------------
get_params( choice="", data_path="dataset/timeseries/", config_mode="test",  **kw)
test( data_path="dataset/", choice="",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_gluon\gluon_ffn.py
----------------methods----------------
Model.__init__(self,  model_pars=None, data_pars=None, compute_pars=None,  **kwargs)

---------------functions---------------
get_params( choice="", data_path="dataset/timeseries/", config_mode="test",  **kw)
test( data_path="dataset/", choice="test01",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_gluon\gluon_prophet.py
----------------methods----------------
Model.__init__(self,  model_pars=None, data_pars=None, compute_pars=None,  )

---------------functions---------------
get_params( choice="", data_path="dataset/", config_mode="test",  **kw)
test( data_path="dataset/", choice="",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_gluon\model_template.py
----------------methods----------------
Model.__init__(self,  model_pars=None, compute_pars=None,  )

---------------functions---------------
get_params( choice=0, data_path="dataset/",  **kw)
test( data_path="dataset/",  )
test2( data_path="dataset/", out_path="GLUON/gluon.png", reset=True,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_gluon\util.py
----------------methods----------------
Model_empty.__init__(self,  model_pars=None, compute_pars=None,  )

---------------functions---------------
_config_process(data_path,  config_mode="test",  )
fit(model,  sess=None, data_pars=None, model_pars=None, compute_pars=None, out_pars=None, session=None,  **kwargs)
get_dataset(data_pars,   )
load(path,   )
log( n=0, m=1,  *s)
metrics(ypred, data_pars,  compute_pars=None, out_pars=None,  **kwargs)
os_package_root_path(filepath,  sublevel=0, path_add="",  )
plot_predict(item_metrics,  out_pars=None,  )
plot_prob_forecasts(ypred,  out_pars=None,  )
predict(model,  sess=None, data_pars=None, compute_pars=None, out_pars=None,  **kwargs)
save(model, path,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_gluon\util_autogluon.py
----------------methods----------------
Model_empty.__init__(self,  model_pars=None, compute_pars=None,  )

---------------functions---------------
_get_dataset_from_aws(  **kw)
fit(model,  data_pars=None, model_pars=None, compute_pars=None, out_pars=None, session=None,  **kwargs)
get_dataset(  **kw)
import_data_fromfile(  **kw)
load(path,   )
log( n=0, m=1,  *s)
metrics(model, ypred, ytrue, data_pars,  compute_pars=None, out_pars=None,  **kwargs)
os_package_root_path(filepath,  sublevel=0, path_add="",  )
predict(model, data_pars,  compute_pars=None, out_pars=None,  **kwargs)
save(model, out_pars,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_gluon\__init__.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\00_template.py
----------------methods----------------
Model.__init__(self,  model_pars=None, data_pars=None, compute_pars=None,  **kwargs)
Model_empty.__init__(self,  model_pars=None, compute_pars=None,  )

---------------functions---------------
_preprocess_XXXX(df,   **kw)
fit(model,  session=None, data_pars=None, model_pars=None, compute_pars=None, out_pars=None,  **kwargs)
get_dataset(  **kw)
get_params( choice=0, data_path="dataset/",  **kw)
load(path,   )
log( n=0, m=1,  *s)
metrics(ypred, data_pars,  compute_pars=None, out_pars=None,  **kwargs)
os_package_root_path(filepath,  sublevel=0, path_add="",  )
path_setup( out_folder="", sublevel=0, data_path="dataset/",  )
predict(model, data_pars,  compute_pars=None, out_pars=None,  **kwargs)
reset_model(  )
save(model, path,   )
test( data_path="dataset/", pars_choice=0,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\00_template_keras.py
----------------methods----------------
Model.__init__(self,  model_pars=None, data_pars=None, compute_pars=None,  **kwargs)
Model_empty.__init__(self,  model_pars=None, compute_pars=None,  )

---------------functions---------------
_preprocess_XXXX(df,   **kw)
fit(model,  session=None, data_pars=None, model_pars=None, compute_pars=None, out_pars=None,  **kwargs)
get_dataset(  **kw)
get_params( choice=0, data_path="dataset/",  **kw)
load(path,   )
log( n=0, m=1,  *s)
metrics(ypred, data_pars,  compute_pars=None, out_pars=None,  **kwargs)
os_package_root_path(filepath,  sublevel=0, path_add="",  )
path_setup( out_folder="", sublevel=0, data_path="dataset/",  )
predict(model, data_pars,  compute_pars=None, out_pars=None,  **kwargs)
reset_model(  )
save(model, path,   )
test( data_path="dataset/", pars_choice=0,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\01_deepctr.py
----------------methods----------------
Model.__init__(self,  model_pars=None, data_pars=None, compute_pars=None,  **kwargs)

---------------functions---------------
_config_process(config,   )
_preprocess_criteo(df,   **kw)
_preprocess_movielens(df,   **kw)
config_load(data_path, file_default, config_mode,   )
fit(model,  session=None, compute_pars=None, data_pars=None, out_pars=None,  **kwargs)
get_dataset( data_pars=None,  **kw)
get_params( choice="", data_path="dataset/", config_mode="test",  **kw)
metrics(ypred,  ytrue=None, session=None, compute_pars=None, data_pars=None, out_pars=None,  **kwargs)
path_setup( out_folder="", sublevel=0, data_path="dataset/",  )
predict(model,  session=None, compute_pars=None, data_pars=None, out_pars=None,  **kwargs)
reset_model(  )
test( data_path="dataset/", pars_choice=0,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\02_cnn.py
----------------methods----------------
Model.__init__(self,  model_pars=None, compute_pars=None, data_pars=None,  )

---------------functions---------------
fit(model,  data_pars=None, model_pars=None, compute_pars=None, out_pars=None, session=None,  **kwargs)
get_dataset(data_params,   **kw)
get_params( choice=0, data_path="dataset/",  **kw)
log( n=0, m=1,  *s)
metrics(ypred, data_pars,  compute_pars=None, out_pars=None,  **kwargs)
os_package_root_path(filepath,  sublevel=0, path_add="",  )
predict(model, data_pars,  compute_pars=None, out_pars=None,  **kwargs)
test( data_path="dataset/",  )
test2( data_path="dataset/", out_path="keras/keras.png", reset=True,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\charcnn.py
----------------methods----------------
Model.__init__(self,  model_pars=None, data_pars=None, compute_pars=None,  )

---------------functions---------------
fit(model,  data_pars=None, compute_pars=None, out_pars=None,  **kw)
fit_metrics(model,  data_pars=None, compute_pars=None, out_pars=None,  **kw)
get_dataset( data_pars=None,  **kw)
get_params( param_pars={},  **kw)
load( load_pars={},  )
predict(model,  sess=None, data_pars=None, out_pars=None, compute_pars=None,  **kw)
reset_model(  )
save( model=None, session=None, save_pars={},  )
test( data_path="dataset/", pars_choice="json", config_mode="test",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\namentity_crm_bilstm.py
----------------methods----------------
Model.__init__(self,  model_pars=None, data_pars=None, compute_pars=None,  **kwargs)

---------------functions---------------
_preprocess_test(data_pars,   **kw)
fit(model,  data_pars=None, compute_pars=None, out_pars=None,  **kw)
fit_metrics(model,  data_pars=None, compute_pars=None, out_pars=None,  **kw)
get_dataset(data_pars,   **kw)
get_params( param_pars={},  **kw)
load(load_pars,   )
predict(model,  sess=None, data_pars=None, out_pars=None, compute_pars=None,  **kw)
reset_model(  )
save( model=None, session=None, save_pars=None,  )
test( data_path="dataset/", pars_choice="json", config_mode="test",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\preprocess.py
----------------methods----------------

---------------functions---------------
_preprocess_criteo(df,   **kw)
_preprocess_movielens(df,   **kw)
_preprocess_none(df,   **kw)
get_dataset(  **kw)
log( n=0, m=1,  *s)
os_package_root_path(filepath,  sublevel=0, path_add="",  )
test( data_path="dataset/", pars_choice=0,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\textcnn.py
----------------methods----------------

---------------functions---------------
fit(model,  data_pars=None, compute_pars=None, out_pars=None,  **kw)
fit_metrics(model,  data_pars=None, compute_pars=None, out_pars=None,  **kw)
get_dataset( data_pars=None,  **kw)
get_params( param_pars={},  **kw)
load( load_pars={},  )
predict(model,  sess=None, data_pars=None, out_pars=None, compute_pars=None,  **kw)
reset_model(  )
save( model=None, session=None, save_pars={},  )
test( data_path="dataset/", pars_choice="json", config_mode="test",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\textvae.py
----------------methods----------------
CustomVariationalLayer.__init__(self,   **kwargs)
CustomVariationalLayer.call(self, inputs,   )
CustomVariationalLayer.vae_loss(self, x, x_decoded_mean,   )
Model.__init__(self,  model_pars=None, data_pars=None, compute_pars=None,  )

---------------functions---------------
fit(model,  data_pars=None, compute_pars=None, out_pars=None,  **kw)
fit_metrics(model,  data_pars=None, compute_pars=None, out_pars=None,  **kw)
get_dataset( data_pars=None,  **kw)
get_params( param_pars={},  **kw)
load( load_pars={},  )
predict(model,  sess=None, data_pars=None, compute_pars=None, out_pars=None,  **kw)
reset_model(  )
save( model=None, session=None, save_pars={},  )
test( data_path="dataset/", pars_choice="json", config_mode="test",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\util.py
----------------methods----------------
Model_empty.__init__(self,  model_pars=None, compute_pars=None,  )

---------------functions---------------
_config_process(data_path,  config_mode="test",  )
fit(model,  data_pars=None, model_pars=None, compute_pars=None, out_pars=None, session=None,  **kwargs)
get_dataset(  **kw)
load(path,   )
log( n=0, m=1,  *s)
metrics(ypred, data_pars,  compute_pars=None, out_pars=None,  **kwargs)
os_package_root_path(filepath,  sublevel=0, path_add="",  )
predict(model, data_pars,  compute_pars=None, out_pars=None,  **kwargs)
save(model, path,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\__init__.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\no_03_textcnn.py
----------------methods----------------

---------------functions---------------
fit(model, Xtrain, ytrain,  compute_pars=None,  **kw)
get_params( choice="", data_path="./dataset/", config_mode="test",  **kw)
get_pre_train_word2vec(model, index2word, vocab_size,   )
load(path,   )
log( n=0, m=1,  *s)
metrics(ytrue, ypred,  data_pars=None, out_pars=None,  **kw)
os_module_path(  )
path_setup( out_folder="", sublevel=0, data_path="dataset/",  )
predict(model, Xtest, ytest,  data_pars=None, out_pars=None, compute_pars=None,  **kw)
reset_model(  )
save(model, path,   )
test( data_path="dataset/", pars_choice="json", reset=True,  )
test2( data_path="dataset/", pars_choice="json", reset=True,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\__init__.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\char_cnn\data_utils.py
----------------methods----------------
Data.__init__(self, data_source,  alphabet="abcdefghijklmnopqrstuvwxyz0123456789-,  )
Data.get_all_data(self,   )
Data.load_data(self,   )
Data.str_to_indexes(self, s,   )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\char_cnn\main.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\char_cnn\models\char_cnn_kim.py
----------------methods----------------
CharCNNKim.__init__(self, input_size, alphabet_size, embedding_size, conv_layers, fully_connected_layers, num_of_classes, dropout_p,  optimizer='adam', loss='categorical_crossentropy',  )
CharCNNKim._build_model(self,   )
CharCNNKim.test(self, testing_inputs, testing_labels, batch_size,   )
CharCNNKim.train(self, training_inputs, training_labels, validation_inputs, validation_labels, epochs, batch_size,  checkpoint_every=100,  )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\char_cnn\models\char_cnn_zhang.py
----------------methods----------------
CharCNNZhang.__init__(self, input_size, alphabet_size, embedding_size, conv_layers, fully_connected_layers, num_of_classes, threshold, dropout_p,  optimizer='adam', loss='categorical_crossentropy',  )
CharCNNZhang._build_model(self,   )
CharCNNZhang.test(self, testing_inputs, testing_labels, batch_size,   )
CharCNNZhang.train(self, training_inputs, training_labels, validation_inputs, validation_labels, epochs, batch_size,  checkpoint_every=100,  )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\char_cnn\models\char_tcn.py
----------------methods----------------
CharTCN.__init__(self, input_size, alphabet_size, embedding_size, conv_layers, fully_connected_layers, num_of_classes, threshold, dropout_p,  optimizer='adam', loss='categorical_crossentropy',  )
CharTCN._build_model(self,   )
CharTCN.test(self, testing_inputs, testing_labels, batch_size,   )
CharTCN.train(self, training_inputs, training_labels, validation_inputs, validation_labels, epochs, batch_size,  checkpoint_every=100,  )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\char_cnn\models\__init__.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\examples\run_classification_criteo.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\examples\run_classification_criteo_hash.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\examples\run_classification_criteo_multi_gpu.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\examples\run_dien.py
----------------methods----------------

---------------functions---------------
get_xy_fd( use_neg=False, hash_flag=False,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\examples\run_din.py
----------------methods----------------

---------------functions---------------
get_xy_fd(  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\examples\run_dsin.py
----------------methods----------------

---------------functions---------------
get_xy_fd( hash_flag=False,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\examples\run_multivalue_movielens.py
----------------methods----------------

---------------functions---------------
split(x,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\examples\run_multivalue_movielens_hash.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\examples\run_regression_movielens.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\FastText\fast_text.py
----------------methods----------------
FastText.__init__(self, maxlen, max_features, embedding_dims,  class_num=1, last_activation='sigmoid',  )
FastText.get_model(self,   )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\FastText\main.py
----------------methods----------------

---------------functions---------------
add_ngram(sequences, token_indice,  ngram_range=2,  )
create_ngram_set(input_list,  ngram_value=2,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\graph_cnn_text\build_graph.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\graph_cnn_text\inits.py
----------------methods----------------

---------------functions---------------
glorot(shape,  name=None,  )
ones(shape,  name=None,  )
uniform(shape,  scale=0.05, name=None,  )
weight_variable_glorot(input_dim, output_dim,  name="",  )
zeros(shape,  name=None,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\graph_cnn_text\layers.py
----------------methods----------------
Dense.__init__(self, input_dim, output_dim, placeholders,  dropout=0., sparse_inputs=False, act=tf.nn.relu, bias=False, featureless=False,  **kwargs)
Dense._call(self, inputs,   )
GraphConvolution.__init__(self, input_dim, output_dim, placeholders,  dropout=0., sparse_inputs=False, act=tf.nn.relu, bias=False, featureless=False,  **kwargs)
GraphConvolution._call(self, inputs,   )
Layer.__call__(self, inputs,   )
Layer.__init__(self,  edge_type=(), num_types=-1,  **kwargs)
Layer._call(self, inputs,   )
Layer._log_vars(self,   )

---------------functions---------------
dot(x, y,  sparse=False,  )
dropout_sparse(x, keep_prob, num_nonzero_elems,   )
get_layer_uid( layer_name='',  )
sparse_dropout(x, keep_prob, noise_shape,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\graph_cnn_text\metrics.py
----------------methods----------------

---------------functions---------------
masked_accuracy(preds, labels, mask,   )
masked_softmax_cross_entropy(preds, labels, mask,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\graph_cnn_text\models.py
----------------methods----------------
GCN.__init__(self, placeholders, input_dim,   **kwargs)
GCN._accuracy(self,   )
GCN._build(self,   )
GCN._loss(self,   )
GCN.predict(self,   )
Model.__init__(self,   **kwargs)
Model._accuracy(self,   )
Model._build(self,   )
Model._loss(self,   )
Model.build(self,   )
Model.load(self,  sess=None,  )
Model.predict(self,   )
Model.save(self,  sess=None,  )
RGCN.__init__(self, placeholders, num_feat, nonzero_feat, edge_types,   **kwargs)
RGCN._accuracy(self,   )
RGCN._build(self,   )
RGCN._loss(self,   )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\graph_cnn_text\remove_words.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\graph_cnn_text\train.py
----------------methods----------------

---------------functions---------------
evaluate(features, support, labels, mask, placeholders,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\graph_cnn_text\tsne.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\graph_cnn_text\utils.py
----------------methods----------------

---------------functions---------------
build_feed_dict(labels, labels_mask, adj, edge_types, feat, placeholders,   )
chebyshev_polynomials(adj, k,   )
clean_str(string,   )
construct_feed_dict(features, support, labels, labels_mask, placeholders,   )
loadWord2Vec(filename,   )
load_corpus(dataset_str,   )
load_corpus_kg(dataset_str,   )
load_corpus_multimodal(dataset_str,   )
load_data(dataset_str,   )
normalize_adj(adj,  symmetric=True,  )
parse_index_file(filename,   )
preprocess_adj(adj,   )
preprocess_features(features,   )
preprocess_graph(adj,  symmetric=True,  )
read_triples(file_path,   )
sample_mask(idx, l,   )
sparse_to_tuple(sparse_mx,   )
synonimize(word,  pos=None,  )
word_synonyms(word,   )
wordnet_defs(  )
wordnet_id_num_dict(  )
wordnet_id_synset_dict(  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\graph_cnn_text\__init__.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\HAN\attention.py
----------------methods----------------
Attention.__init__(self, step_dim,  W_regularizer=None, b_regularizer=None, W_constraint=None, b_constraint=None, bias=True,  **kwargs)
Attention.build(self, input_shape,   )
Attention.call(self, x,  mask=None,  )
Attention.compute_mask(self, input,  input_mask=None,  )
Attention.compute_output_shape(self, input_shape,   )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\HAN\han.py
----------------methods----------------
HAN.__init__(self, maxlen_sentence, maxlen_word, max_features, embedding_dims,  class_num=1, last_activation='sigmoid',  )
HAN.get_model(self,   )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\HAN\main.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\RCNN\main.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\RCNN\rcnn.py
----------------methods----------------
RCNN.__init__(self, maxlen, max_features, embedding_dims,  class_num=1, last_activation='sigmoid',  )
RCNN.get_model(self,   )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\RCNNVariant\main.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\RCNNVariant\rcnn_variant.py
----------------methods----------------
RCNNVariant.__init__(self, maxlen, max_features, embedding_dims,  class_num=1, last_activation='sigmoid',  )
RCNNVariant.get_model(self,   )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\TextAttBiRNN\attention.py
----------------methods----------------
Attention.__init__(self, step_dim,  W_regularizer=None, b_regularizer=None, W_constraint=None, b_constraint=None, bias=True,  **kwargs)
Attention.build(self, input_shape,   )
Attention.call(self, x,  mask=None,  )
Attention.compute_mask(self, input,  input_mask=None,  )
Attention.compute_output_shape(self, input_shape,   )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\TextAttBiRNN\main.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\TextAttBiRNN\text_att_birnn.py
----------------methods----------------
TextAttBiRNN.__init__(self, maxlen, max_features, embedding_dims,  class_num=1, last_activation='sigmoid',  )
TextAttBiRNN.get_model(self,   )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\TextBiRNN\main.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\TextBiRNN\text_birnn.py
----------------methods----------------
TextBiRNN.__init__(self, maxlen, max_features, embedding_dims,  class_num=1, last_activation='sigmoid',  )
TextBiRNN.get_model(self,   )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\textcnn_\main.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\textcnn_\text_cnn.py
----------------methods----------------
TextCNN.__init__(self, maxlen, max_features, embedding_dims,  class_num=1, last_activation='sigmoid',  )
TextCNN.get_model(self,   )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\textcnn_\__init__.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\TextRNN\main.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\TextRNN\text_rnn.py
----------------methods----------------
TextRNN.__init__(self, maxlen, max_features, embedding_dims,  class_num=1, last_activation='sigmoid',  )
TextRNN.get_model(self,   )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\text_graph_cnn2\bow.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\text_graph_cnn2\build_corpus.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\text_graph_cnn2\build_graph.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\text_graph_cnn2\doc2vec.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\text_graph_cnn2\inits.py
----------------methods----------------

---------------functions---------------
glorot(shape,  name=None,  )
ones(shape,  name=None,  )
uniform(shape,  scale=0.05, name=None,  )
zeros(shape,  name=None,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\text_graph_cnn2\layers.py
----------------methods----------------
Dense.__init__(self, input_dim, output_dim, placeholders,  dropout=0., sparse_inputs=False, act=tf.nn.relu, bias=False, featureless=False,  **kwargs)
Dense._call(self, inputs,   )
GraphConvolution.__init__(self, input_dim, output_dim, placeholders,  dropout=0., sparse_inputs=False, act=tf.nn.relu, bias=False, featureless=False,  **kwargs)
GraphConvolution._call(self, inputs,   )
Layer.__call__(self, inputs,   )
Layer.__init__(self,   **kwargs)
Layer._call(self, inputs,   )
Layer._log_vars(self,   )

---------------functions---------------
dot(x, y,  sparse=False,  )
get_layer_uid( layer_name='',  )
sparse_dropout(x, keep_prob, noise_shape,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\text_graph_cnn2\metrics.py
----------------methods----------------

---------------functions---------------
masked_accuracy(preds, labels, mask,   )
masked_softmax_cross_entropy(preds, labels, mask,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\text_graph_cnn2\models.py
----------------methods----------------
GCN.__init__(self, placeholders, input_dim,   **kwargs)
GCN._accuracy(self,   )
GCN._build(self,   )
GCN._loss(self,   )
GCN.predict(self,   )
MLP.__init__(self, placeholders, input_dim,   **kwargs)
MLP._accuracy(self,   )
MLP._build(self,   )
MLP._loss(self,   )
MLP.predict(self,   )
Model.__init__(self,   **kwargs)
Model._accuracy(self,   )
Model._build(self,   )
Model._loss(self,   )
Model.build(self,   )
Model.load(self,  sess=None,  )
Model.predict(self,   )
Model.save(self,  sess=None,  )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\text_graph_cnn2\plot_dim.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\text_graph_cnn2\plot_prop.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\text_graph_cnn2\plot_window.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\text_graph_cnn2\prepare_data.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\text_graph_cnn2\remove_words.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\text_graph_cnn2\train.py
----------------methods----------------

---------------functions---------------
evaluate(features, support, labels, mask, placeholders,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\text_graph_cnn2\utils.py
----------------methods----------------

---------------functions---------------
chebyshev_polynomials(adj, k,   )
clean_str(string,   )
construct_feed_dict(features, support, labels, labels_mask, placeholders,   )
loadWord2Vec(filename,   )
load_corpus(dataset_str,   )
load_data(dataset_str,   )
normalize_adj(adj,   )
parse_index_file(filename,   )
preprocess_adj(adj,   )
preprocess_features(features,   )
sample_mask(idx, l,   )
sparse_to_tuple(sparse_mx,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\text_graph_cnn2\visualize.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\text_graph_cnn2\visualize_words.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\text_graph_cnn2\wordnet.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_keras\raw\text_graph_cnn2\__init__.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_rank\LambdaRank.py
----------------methods----------------
LambdaRank.__init__(self, net_structures,  leaky_relu=False, sigma=1.0, double_precision=False,  )
LambdaRank.dump_param(self,   )
LambdaRank.forward(self, input1,   )

---------------functions---------------
train( start_epoch=0, additional_epoch=100, lr=0.0001, optim="adam", leaky_relu=False, ndcg_gain_in_train="exp2", sigma=1.0, double_precision=False, standardize=False, small_dataset=False, debug=False,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_rank\load_mslr.py
----------------methods----------------
DataLoader.__init__(self, path,   )
DataLoader._load_mslr(self,   )
DataLoader._parse_feature_and_label(self, df,   )
DataLoader.apply_scaler(self, scaler,   )
DataLoader.generate_batch_per_query(self,  df=None,  )
DataLoader.generate_query_batch(self, df,  batchsize=100000,  )
DataLoader.generate_query_pair_batch(self,  df=None, batchsize=2000,  )
DataLoader.generate_query_pairs(self, df, qid,   )
DataLoader.get_num_pairs(self,   )
DataLoader.get_num_sessions(self,   )
DataLoader.load(self,   )
DataLoader.train_scaler_and_transform(self,   )

---------------functions---------------
get_time(  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_rank\metrics.py
----------------methods----------------
DCG.__init__(self,  k=10, gain_type='exp2',  )
DCG._get_discount(self, k,   )
DCG._get_gain(self, targets,   )
DCG._make_discount(n,   )
DCG.evaluate(self, targets,   )
NDCG.__init__(self,  k=10, gain_type='exp2',  )
NDCG.evaluate(self, targets,   )
NDCG.maxDCG(self, targets,   )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_rank\RankNet.py
----------------methods----------------
RankNet.__init__(self, net_structures,  double_precision=False,  )
RankNet.dump_param(self,   )
RankNet.forward(self, input1,   )
RankNetPairs.__init__(self, net_structures,  double_precision=False,  )
RankNetPairs.forward(self, input1, input2,   )

---------------functions---------------
baseline_pairwise_training_loop(epoch, net, loss_func, optimizer, train_loader,  batch_size=100000, precision=torch.float32, device="cpu", debug=False,  )
eval_model(inference_model, device, df_valid, valid_loader,   )
factorized_training_loop(epoch, net, loss_func, optimizer, train_loader,  batch_size=200, sigma=1.0, training_algo=SUM_SESSION, precision=torch.float32, device="cpu", debug=False,  )
get_train_inference_net(train_algo, num_features, start_epoch, double_precision,   )
load_from_ckpt(ckpt_file, epoch, model,   )
train_rank_net( start_epoch=0, additional_epoch=100, lr=0.0001, optim="adam", train_algo=SUM_SESSION, double_precision=False, standardize=False, small_dataset=False, debug=False,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_rank\utils.py
----------------methods----------------

---------------functions---------------
eval_cross_entropy_loss(model, device, loader,  phase="Eval", sigma=1.0,  )
eval_ndcg_at_k(inference_model, device, df_valid, valid_loader, batch_size, k_list,  phase="Eval",  )
get_args_parser(  )
get_ckptdir(net_name, net_structure,  sigma=None,  )
get_device(  )
init_weights(m,   )
load_train_vali_data(data_fold,  small_dataset=False,  )
save_to_ckpt(ckpt_file, epoch, model, optimizer, lr_scheduler,   )
str2bool(v,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_rank\__init__.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_rank\dev\LambdaRank.py
----------------methods----------------
LambdaRank.__init__(self, net_structures,  leaky_relu=False, sigma=1.0, double_precision=False,  )
LambdaRank.dump_param(self,   )
LambdaRank.forward(self, input1,   )

---------------functions---------------
train( start_epoch=0, additional_epoch=100, lr=0.0001, optim="adam", leaky_relu=False, ndcg_gain_in_train="exp2", sigma=1.0, double_precision=False, standardize=False, small_dataset=False, debug=False,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_rank\dev\load_mslr.py
----------------methods----------------
DataLoader.__init__(self, path,   )
DataLoader._load_mslr(self,   )
DataLoader._parse_feature_and_label(self, df,   )
DataLoader.apply_scaler(self, scaler,   )
DataLoader.generate_batch_per_query(self,  df=None,  )
DataLoader.generate_query_batch(self, df,  batchsize=100000,  )
DataLoader.generate_query_pair_batch(self,  df=None, batchsize=2000,  )
DataLoader.generate_query_pairs(self, df, qid,   )
DataLoader.get_num_pairs(self,   )
DataLoader.get_num_sessions(self,   )
DataLoader.load(self,   )
DataLoader.train_scaler_and_transform(self,   )

---------------functions---------------
get_time(  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_rank\dev\metrics.py
----------------methods----------------
DCG.__init__(self,  k=10, gain_type='exp2',  )
DCG._get_discount(self, k,   )
DCG._get_gain(self, targets,   )
DCG._make_discount(n,   )
DCG.evaluate(self, targets,   )
NDCG.__init__(self,  k=10, gain_type='exp2',  )
NDCG.evaluate(self, targets,   )
NDCG.maxDCG(self, targets,   )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_rank\dev\RankNet.py
----------------methods----------------
RankNet.__init__(self, net_structures,  double_precision=False,  )
RankNet.dump_param(self,   )
RankNet.forward(self, input1,   )
RankNetPairs.__init__(self, net_structures,  double_precision=False,  )
RankNetPairs.forward(self, input1, input2,   )

---------------functions---------------
baseline_pairwise_training_loop(epoch, net, loss_func, optimizer, train_loader,  batch_size=100000, precision=torch.float32, device="cpu", debug=False,  )
eval_model(inference_model, device, df_valid, valid_loader,   )
factorized_training_loop(epoch, net, loss_func, optimizer, train_loader,  batch_size=200, sigma=1.0, training_algo=SUM_SESSION, precision=torch.float32, device="cpu", debug=False,  )
get_train_inference_net(train_algo, num_features, start_epoch, double_precision,   )
load_from_ckpt(ckpt_file, epoch, model,   )
train_rank_net( start_epoch=0, additional_epoch=100, lr=0.0001, optim="adam", train_algo=SUM_SESSION, double_precision=False, standardize=False, small_dataset=False, debug=False,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_rank\dev\utils.py
----------------methods----------------

---------------functions---------------
eval_cross_entropy_loss(model, device, loader,  phase="Eval", sigma=1.0,  )
eval_ndcg_at_k(inference_model, device, df_valid, valid_loader, batch_size, k_list,  phase="Eval",  )
get_args_parser(  )
get_ckptdir(net_name, net_structure,  sigma=None,  )
get_device(  )
init_weights(m,   )
load_train_vali_data(data_fold,  small_dataset=False,  )
save_to_ckpt(ckpt_file, epoch, model, optimizer, lr_scheduler,   )
str2bool(v,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_sklearn\lightgbm.py
----------------methods----------------
Model.__init__(self,  model_pars=None, data_pars=None, compute_pars=None,  )

---------------functions---------------
fit(model,  data_pars=None, compute_pars=None, out_pars=None,  **kw)
fit_metrics(model,  data_pars=None, compute_pars=None, out_pars=None,  **kw)
get_dataset( data_pars=None,  **kw)
get_params( param_pars={},  **kw)
load( load_pars={},  )
path_setup( out_folder="ztest", sublevel=0, data_path="dataset/",  )
predict(model,  sess=None, data_pars=None, compute_pars=None, out_pars=None,  **kw)
reset_model(  )
save( model=None, session=None, save_pars={},  )
test( data_path="dataset/", pars_choice="json", config_mode="test",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_sklearn\model.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_sklearn\model_lightgbm.py
----------------methods----------------
Model.__init__(self,  model_pars=None, data_pars=None, compute_pars=None,  )

---------------functions---------------
fit(model,  data_pars=None, compute_pars=None, out_pars=None,  **kw)
fit_metrics(model,  data_pars=None, compute_pars=None, out_pars=None,  **kw)
get_dataset( data_pars=None,  **kw)
get_params( param_pars={},  **kw)
load( load_pars=None,  )
predict(model,  sess=None, data_pars=None, compute_pars=None, out_pars=None,  **kw)
reset_model(  )
save( model=None, session=None, save_pars=None,  )
test( data_path="dataset/", pars_choice="json", config_mode="test",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_sklearn\model_sklearn.py
----------------methods----------------
Model.__init__(self,  model_pars=None, data_pars=None, compute_pars=None,  )

---------------functions---------------
fit(model,  data_pars=None, compute_pars=None, out_pars=None,  **kw)
fit_metrics(model,  data_pars=None, compute_pars=None, out_pars=None,  **kw)
get_dataset( data_pars=None,  **kw)
get_params( param_pars={},  **kw)
load( load_pars={},  )
predict(model,  sess=None, data_pars=None, compute_pars=None, out_pars=None,  **kw)
reset_model(  )
save( model=None, session=None, save_pars={},  )
test( data_path="dataset/", pars_choice="json", config_mode="test",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_sklearn\sklearn.py
----------------methods----------------
Model.__init__(self,  model_pars=None, data_pars=None, compute_pars=None,  )

---------------functions---------------
fit(model,  data_pars=None, compute_pars=None, out_pars=None,  **kw)
fit_metrics(model,  data_pars=None, compute_pars=None, out_pars=None,  **kw)
get_dataset( data_pars=None,  **kw)
get_params( param_pars={},  **kw)
load( load_pars={},  )
path_setup( out_folder="ztest", sublevel=0, data_path="dataset/",  )
predict(model,  sess=None, data_pars=None, compute_pars=None, out_pars=None,  **kw)
reset_model(  )
save( model=None, session=None, save_pars={},  )
test( data_path="dataset/", pars_choice="json", config_mode="test",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_sklearn\__init__.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\02_mlp.py
----------------methods----------------
Model.__init__(self,   )
Model.forward(self, x,   )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\03_nbeats.py
----------------methods----------------

---------------functions---------------
data_generator(x_full, y_full, bs,   )
fit(model,  data_pars=None, compute_pars=None, out_pars=None,  **kw)
fit_simple(net, optimiser, data_generator, on_save_callback, device, data_pars, out_pars,  max_grad_steps=500,  )
get_dataset(  **kw)
get_params(param_pars,   **kw)
load(load_pars,   )
load_checkpoint(model, optimiser,  CHECKPOINT_NAME='nbeats-fiting-checkpoint.th',  )
plot(net, x, target, backcast_length, forecast_length, grad_step,  out_path="./",  )
plot_model(net, x, target, grad_step, data_pars,  disable_plot=False,  )
plot_predict(x_test, y_test, p, data_pars, compute_pars, out_pars,   )
predict(model,  data_pars=None, compute_pars=None, out_pars=None,  **kw)
save(model, session, save_pars,   )
save_checkpoint(model, optimiser, grad_step,  CHECKPOINT_NAME="mycheckpoint",  )
test( data_path="dataset/milk.csv",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\cnn_classifier.py
----------------methods----------------
Model.__init__(self,   )
Model.forward(self, x,   )
Model.log_weights(self, step,   )
Model.to(  *arg, **kwarg)

---------------functions---------------
_eval_metrics(model, epoch, test_loader,   )
_log_scalar(name, value, step,   )
_train(epoch, model, train_loader,   )
cli_load_arguments(  )
fit(model, data_pars,  compute_pars=None, out_pars=None,  **kwargs)
get_dataset(data_params,   )
get_pars( choice="test",  **kwargs)
metrics(model,  sess=None, data_params={}, compute_params={},  )
predict(model,  sess=None, compute_params=None, data_params=None,  )
predict_proba(model,  sess=None, compute_params=None, data_params=None,  )
test(arg,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\data_prep.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\mlp.py
----------------methods----------------
Model.__init__(self,   )
Model.forward(self, x,   )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\nbeats.py
----------------methods----------------

---------------functions---------------
data_generator(x_full, y_full, bs,   )
fit(model,  data_pars=None, compute_pars=None, out_pars=None,  **kw)
fit_simple(net, optimiser, data_generator, on_save_callback, device, data_pars,  max_grad_steps=500,  )
get_dataset(  **kw)
get_params( choice=0, data_path="dataset/", config_mode="test",  **kw)
load(model, optimiser,  CHECKPOINT_NAME='nbeats-fiting-checkpoint.th',  )
log( n=0, m=1,  *s)
os_package_root_path(filepath,  sublevel=0, path_add="",  )
plot(net, x, target, backcast_length, forecast_length, grad_step,  out_path="./",  )
plot_model(net, x, target, grad_step, data_pars,  disable_plot=False,  )
plot_predict(x_test, y_test, p, data_pars, compute_pars, out_pars,   )
predict(model,  data_pars=None, compute_pars=None, out_pars=None,  **kw)
save(model, optimiser, grad_step,  CHECKPOINT_NAME="mycheckpoint",  )
test( data_path="dataset/milk.csv",  )
test2( data_path="dataset/milk.csv", out_path="n_beats_test{}.png", reset=True,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\pplm.py
----------------methods----------------

---------------functions---------------
fit(model,  data_pars=None, compute_pars=None, out_pars=None,  **kw)
generate(cond_text, bag_of_words,  discrim=None, class_label=-1,  )
get_dataset( data_pars=None,  **kw)
get_params( param_pars=None,  **kw)
path_setup( out_folder="", sublevel=0, data_path="dataset/",  )
predict(model,  sess=None, data_pars=None, compute_pars=None, out_pars=None,  **kw)


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\sentence_transformer.py
----------------methods----------------
Model.__init__(self, args, device,   )
Model_empty.__init__(self,  model_pars=None, compute_pars=None,  )

---------------functions---------------
_preprocess_XXXX(df,   **kw)
evaluate(model, tokenizer,  prefix="",  )
fit(train_dataset, model, tokenizer,   )
get_dataset(task, tokenizer,  evaluate=False,  )
get_eval_report(labels, preds,   )
get_mismatched(labels, preds,   )
get_params( choice=0, data_path="dataset/",  **kw)
load(path,   )
log( n=0, m=1,  *s)
metrics(task_name, preds, labels,   )
os_package_root_path(filepath,  sublevel=0, path_add="",  )
path_setup( out_folder="", sublevel=0, data_path="dataset/",  )
predict(model, data_pars,  compute_pars=None, out_pars=None,  **kwargs)
reset_model(  )
save(model, path,   )
test( data_path="dataset/", pars_choice=0,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\textcnn.py
----------------methods----------------
TextCNN.__init__(self,  model_pars=None,  **kwargs)
TextCNN.forward(self, x,   )
TextCNN.rebuild_embed(self, vocab_built,   )
TextCNN.tokenizer(text,   )

---------------functions---------------
_get_device(  )
_train(m, device, train_itr, optimizer, epoch, max_epoch,   )
_valid(m, device, test_itr,   )
clean_str(string,   )
create_data_iterator(tr_batch_size, val_batch_size, tabular_train, tabular_valid, d,   )
create_tabular_dataset(path_train, path_valid,  lang='en', pretrained_emb='glove.6B.300d',  )
fit(model,  sess=None, data_pars=None, compute_pars=None, out_pars=None,  **kwargs)
get_config_file(  )
get_data_file(  )
get_dataset( data_pars=None, out_pars=None,  **kwargs)
get_params( param_pars=None,  **kw)
load(path,   )
metric(model,  data_pars=None, out_pars=None,  **kwargs)
predict(model,  data_pars=None, compute_pars=None, out_pars=None,  )
save(model, path,   )
split_train_valid(path_data, path_train, path_valid,  frac=0.7,  )
test(  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\torchhub.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\transformer_classifier.py
----------------methods----------------
Model.__init__(self,  model_pars=None, data_pars=None, compute_pars=None,  )

---------------functions---------------
_preprocess_XXXX(df,   **kw)
fit(train_dataset, model, tokenizer,   )
fit_metrics(model, tokenizer, model_pars, data_pars, out_pars, compute_pars,  prefix="",  )
get_dataset(task, tokenizer,  evaluate=False,  )
get_eval_report(labels, preds,   )
get_mismatched(labels, preds,   )
get_params( param_pars={},  **kw)
load( load_pars={},  )
load_and_cache_examples(task, tokenizer,  evaluate=False,  )
metrics(task_name, preds, labels,   )
reset_model(  )
save( model=None, session=None, save_pars={},  )
test(data_path, model_pars, data_pars, compute_pars, out_pars,  pars_choice=0,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\transformer_classifier2.py
----------------methods----------------
Model_empty.__init__(self,  model_pars=None, compute_pars=None,  )

---------------functions---------------
_preprocess_XXXX(df,   **kw)
evaluate(model, tokenizer,  prefix="",  )
fit(model,  data_pars=None, model_pars={}, compute_pars=None, out_pars=None,  *args, **kw)
get_dataset( data_pars=None,  **kw)
get_eval_report(labels, preds,   )
get_mismatched(labels, preds,   )
get_params( choice=0, data_path="dataset/",  **kw)
load( out_pars=None,  )
metrics(task_name, preds, labels,   )
metrics_evaluate(  )
path_setup( out_folder="", sublevel=0, data_path="dataset/",  )
predict(model,  sess=None, data_pars=None, out_pars=None, compute_pars=None,  **kw)
reset_model(  )
save(model, out_pars,   )
test( data_path="dataset/", pars_choice=0,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\transformer_sentence.py
----------------methods----------------

---------------functions---------------
fit(model,  data_pars=None, model_pars={}, compute_pars=None, out_pars=None,  *args, **kw)
fit_metrics(model,   **kw)
get_dataset( data_pars=None,  **kw)
get_params(param_pars,   **kw)
load( out_pars=None,  )
predict(model,  sess=None, data_pars=None, out_pars=None, compute_pars=None,  **kw)
reset_model(  )
save(model, out_pars,   )
test( data_path="dataset/", pars_choice="test01",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\util_data.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\util_transformer.py
----------------methods----------------
BinaryProcessor._create_examples(self, lines, set_type,   )
BinaryProcessor.get_dev_examples(self, data_dir,   )
BinaryProcessor.get_labels(self,   )
BinaryProcessor.get_train_examples(self, data_dir,   )
DataProcessor._read_tsv(cls, input_file,  quotechar=None,  )
DataProcessor.get_dev_examples(self, data_dir,   )
DataProcessor.get_labels(self,   )
DataProcessor.get_train_examples(self, data_dir,   )
InputExample.__init__(self, guid, text_a,  text_b=None, label=None,  )
InputFeatures.__init__(self, input_ids, input_mask, segment_ids, label_id,   )

---------------functions---------------
_truncate_seq_pair(tokens_a, tokens_b, max_length,   )
convert_example_to_feature(example_row,  pad_token=0, sequence_a_segment_id=0, sequence_b_segment_id=1, cls_token_segment_id=1, pad_token_segment_id=0, mask_padding_with_zero=True, sep_token_extra=False,  )
convert_examples_to_features(examples, label_list, max_seq_length, tokenizer, output_mode,  cls_token_at_end=False, sep_token_extra=False, pad_on_left=False, cls_token='[CLS]', sep_token='[SEP]', pad_token=0, sequence_a_segment_id=0, sequence_b_segment_id=1, cls_token_segment_id=1, pad_token_segment_id=0, mask_padding_with_zero=True, process_count=cpu_count(),  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\__init__.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\nbeats\data.py
----------------methods----------------

---------------functions---------------
get_data(num_samples, backcast_length, forecast_length,  signal_type='seasonality', random=False,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\nbeats\model.py
----------------methods----------------
Block.__init__(self, units, thetas_dim, device,  backcast_length=10, forecast_length=5, share_thetas=False,  )
Block.__str__(self,   )
Block.forward(self, x,   )
GenericBlock.__init__(self, units, thetas_dim, device,  backcast_length=10, forecast_length=5,  )
GenericBlock.forward(self, x,   )
NBeatsNet.__init__(self, device,  stack_types=[TREND_BLOCK, SEASONALITY_BLOCK], nb_blocks_per_stack=3, forecast_length=5, backcast_length=10, thetas_dims=[4, 8], share_weights_in_stack=False, hidden_layer_units=256,  )
NBeatsNet.create_stack(self, stack_id,   )
NBeatsNet.forward(self, backcast,   )
NBeatsNet.select_block(block_type,   )
SeasonalityBlock.__init__(self, units, thetas_dim, device,  backcast_length=10, forecast_length=5,  )
SeasonalityBlock.forward(self, x,   )
TrendBlock.__init__(self, units, thetas_dim, device,  backcast_length=10, forecast_length=5,  )
TrendBlock.forward(self, x,   )

---------------functions---------------
linspace(backcast_length, forecast_length,   )
seasonality_model(thetas, t, device,   )
trend_model(thetas, t, device,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\nbeats\nbeats.py
----------------methods----------------
Model.__init__(self,  learning_rate=0.001, num_layers=2, size=None, size_layer=128, output_size=None, forget_bias=0.1, timestep=5, epoch=5,  )
Model.plot_model(x, target, grad_step,   )

---------------functions---------------
fit(model, data_pars,   )
fit(model, data_pars,   )
get_script_arguments(  )
load(model, optimiser,   )
plot(net, x, target, backcast_length, forecast_length, grad_step,   )
predict(model, sess, data_pars,   )
reset_model(  )
save(model, optimiser, grad_step,   )
simple_fit(net, optimiser, data_generator, on_save_callback, device,  max_grad_steps=10000,  )
stats_compute(model, sess, df,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\nbeats\nbeats_sample.py
----------------methods----------------

---------------functions---------------
data_generator(x_full, y_full, bs,   )
data_load(  )
eval_test(backcast_length, forecast_length, net, norm_constant, test_losses, x_test, y_test,   )
fit(  )
plot_scatter(  *args, **kwargs)
train_100_grad_steps(data, device, net, optimiser, test_losses,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\nbeats\trainer.py
----------------methods----------------

---------------functions---------------
fit(  )
get_script_arguments(  )
load(model, optimiser,   )
plot(net, x, target, backcast_length, forecast_length, grad_step,   )
save(model, optimiser, grad_step,   )
simple_fit(net, optimiser, data_generator, on_save_callback, device,  max_grad_steps=10000,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\nbeats\__init__.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\pplm\pplm_classification_head.py
----------------methods----------------
ClassificationHead.__init__(self, class_size, embed_size,   )
ClassificationHead.forward(self, hidden_state,   )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\pplm\run_pplm.py
----------------methods----------------

---------------functions---------------
full_text_generation(model, tokenizer,  context=None, num_samples=1, device="cuda", bag_of_words=None, discrim=None, class_label=None, length=100, stepsize=0.02, temperature=1.0, top_k=10, sample=True, num_iterations=3, grad_length=10000, horizon_length=1, window_length=0, decay=False, gamma=1.5, gm_scale=0.9, kl_scale=0.01, verbosity_level=REGULAR,  **kwargs)
generate_text_pplm(model, tokenizer,  context=None, past=None, device="cuda", perturb=True, bow_indices=None, classifier=None, class_label=None, loss_type=0, length=100, stepsize=0.02, temperature=1.0, top_k=10, sample=True, num_iterations=3, grad_length=10000, horizon_length=1, window_length=0, decay=False, gamma=1.5, gm_scale=0.9, kl_scale=0.01, verbosity_level=REGULAR,  )
get_bag_of_words_indices(bag_of_words_ids_or_paths,   )
get_classifier(name,   )
perturb_past(past, model, last,  unpert_past=None, unpert_logits=None, accumulated_hidden=None, grad_norms=None, stepsize=0.01, one_hot_bows_vectors=None, classifier=None, class_label=None, loss_type=0, num_iterations=3, horizon_length=1, window_length=0, decay=False, gamma=1.5, kl_scale=0.01, device='cuda', verbosity_level=REGULAR,  )
run_pplm_example( pretrained_model="gpt2-medium", cond_text="", uncond=False, num_samples=1, bag_of_words=None, discrim=None, discrim_weights=None, discrim_meta=None, class_label=-1, length=100, stepsize=0.02, temperature=1.0, top_k=10, sample=True, num_iterations=3, grad_length=10000, horizon_length=1, window_length=0, decay=False, gamma=1.5, gm_scale=0.9, kl_scale=0.01, seed=0, no_cuda=False, colorama=False, verbosity='regular',  )
set_generic_model_params(discrim_weights, discrim_meta,   )
to_var(x,  requires_grad=False, volatile=False, device='cuda',  )
top_k_filter(logits, k,  probs=False,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\pplm\run_pplm_discrim_train.py
----------------methods----------------
Dataset.__getitem__(self, index,   )
Dataset.__init__(self, X, y,   )
Dataset.__len__(self,   )
Dataset.pad_sequences(sequences,   )
Discriminator.__init__(self, class_size,  pretrained_model="gpt2-medium", cached_mode=False, device='cpu',  )
Discriminator.avg_representation(self, x,   )
Discriminator.forward(self, x,   )
Discriminator.get_classifier(self,   )
Discriminator.train_custom(self,   )

---------------functions---------------
cached_collate_fn(data,   )
collate_fn(data,   )
evaluate_performance(data_loader, discriminator,  device='cpu',  )
get_cached_data_loader(dataset, batch_size, discriminator,  shuffle=False, device='cpu',  )
predict(input_sentence, model, classes,  cached=False, device='cpu',  )
train_discriminator(dataset,  dataset_fp=None, pretrained_model="gpt2-medium", epochs=10, batch_size=64, log_interval=10, save_model=False, cached=False, no_cuda=False,  )
train_epoch(data_loader, discriminator, optimizer,  epoch=0, log_interval=10, device='cpu',  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\pplm\__init__.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\pplm\pplm_transformer\pplm.py
----------------methods----------------
ClassificationHead.__init__(self, class_size, embed_size,   )
ClassificationHead.forward(self, hidden_state,   )
Model.__init__(self, args, device,   )
Model.add(  *k, **kw)

---------------functions---------------
full_text_generation(model, tokenizer,  context=None, num_samples=1, device="cuda", bag_of_words=None, discrim=None, class_label=None, length=100, stepsize=0.02, temperature=1.0, top_k=10, sample=False, num_iterations=3, grad_length=10000, horizon_length=1, window_length=0, decay=False, gamma=1.5, gm_scale=0.9, kl_scale=0.01, repetition_penalty=1.0,  **kwargs)
generate_text_pplm(model, tokenizer,  context=None, past=None, device="cuda", perturb=True, bow_indices=None, classifier=None, class_label=None, loss_type=0, length=100, stepsize=0.02, temperature=1.0, top_k=10, sample=False, num_iterations=3, grad_length=10000, horizon_length=1, window_length=0, decay=False, gamma=1.5, gm_scale=0.9, kl_scale=0.01, repetition_penalty=1.0,  )
get_bag_of_words_indices(bag_of_words_ids_or_paths,   )
get_classifier(name,   )
perturb_past(past, model, last,  unpert_past=None, unpert_logits=None, accumulated_hidden=None, grad_norms=None, stepsize=0.01, one_hot_bows_vectors=None, classifier=None, class_label=None, loss_type=0, num_iterations=3, horizon_length=1, window_length=0, decay=False, gamma=1.5, kl_scale=0.01, device="cuda",  )
run_pplm_example( pretrained_model="gpt2-medium", cond_text="", uncond=False, num_samples=1, bag_of_words=None, discrim=None, discrim_weights=None, discrim_meta=None, class_label=-1, length=100, stepsize=0.02, temperature=1.0, top_k=10, sample=False, num_iterations=3, grad_length=10000, horizon_length=1, window_length=0, decay=False, gamma=1.5, gm_scale=0.9, kl_scale=0.01, seed=0, no_cuda=False, colorama=False, repetition_penalty=1.0,  )
set_generic_model_params(discrim_weights, discrim_meta,   )
to_var(x,  requires_grad=False, volatile=False, device="cuda",  )
top_k_filter(logits, k,  probs=False,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\pplm\pplm_transformer\pplm_classification_head.py
----------------methods----------------
ClassificationHead.__init__(self, class_size, embed_size,   )
ClassificationHead.forward(self, hidden_state,   )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\pplm\pplm_transformer\pplm_train.py
----------------methods----------------
Dataset.__getitem__(self, index,   )
Dataset.__init__(self, X, y,   )
Dataset.__len__(self,   )
Dataset.pad_sequences(sequences,   )
Discriminator.__init__(self, class_size,  pretrained_model="gpt2-medium", cached_mode=False, device="cpu",  )
Discriminator.avg_representation(self, x,   )
Discriminator.forward(self, x,   )
Discriminator.get_classifier(self,   )
Discriminator.train_custom(self,   )

---------------functions---------------
cached_collate_fn(data,   )
collate_fn(data,   )
evaluate_performance(data_loader, discriminator,  device="cpu",  )
get_cached_data_loader(dataset, batch_size, discriminator,  shuffle=False, device="cpu",  )
predict(input_sentence, model, classes,  cached=False, device="cpu",  )
train_discriminator(dataset,  dataset_fp=None, pretrained_model="gpt2-medium", epochs=10, batch_size=64, log_interval=10, save_model=False, cached=False, no_cuda=False,  )
train_epoch(data_loader, discriminator, optimizer,  epoch=0, log_interval=10, device="cpu",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\pplm\pplm_transformer\run_pplm.py
----------------methods----------------

---------------functions---------------
full_text_generation(model, tokenizer,  context=None, num_samples=1, device="cuda", bag_of_words=None, discrim=None, class_label=None, length=100, stepsize=0.02, temperature=1.0, top_k=10, sample=False, num_iterations=3, grad_length=10000, horizon_length=1, window_length=0, decay=False, gamma=1.5, gm_scale=0.9, kl_scale=0.01, repetition_penalty=1.0,  **kwargs)
generate_text_pplm(model, tokenizer,  context=None, past=None, device="cuda", perturb=True, bow_indices=None, classifier=None, class_label=None, loss_type=0, length=100, stepsize=0.02, temperature=1.0, top_k=10, sample=False, num_iterations=3, grad_length=10000, horizon_length=1, window_length=0, decay=False, gamma=1.5, gm_scale=0.9, kl_scale=0.01, repetition_penalty=1.0,  )
get_bag_of_words_indices(bag_of_words_ids_or_paths,   )
get_classifier(name,   )
perturb_past(past, model, last,  unpert_past=None, unpert_logits=None, accumulated_hidden=None, grad_norms=None, stepsize=0.01, one_hot_bows_vectors=None, classifier=None, class_label=None, loss_type=0, num_iterations=3, horizon_length=1, window_length=0, decay=False, gamma=1.5, kl_scale=0.01, device="cuda",  )
run_pplm_example( pretrained_model="gpt2-medium", cond_text="", uncond=False, num_samples=1, bag_of_words=None, discrim=None, discrim_weights=None, discrim_meta=None, class_label=-1, length=100, stepsize=0.02, temperature=1.0, top_k=10, sample=False, num_iterations=3, grad_length=10000, horizon_length=1, window_length=0, decay=False, gamma=1.5, gm_scale=0.9, kl_scale=0.01, seed=0, no_cuda=False, colorama=False, repetition_penalty=1.0,  )
set_generic_model_params(discrim_weights, discrim_meta,   )
to_var(x,  requires_grad=False, volatile=False, device="cuda",  )
top_k_filter(logits, k,  probs=False,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\pplm\pplm_transformer\run_pplm_discrim_train.py
----------------methods----------------
Dataset.__getitem__(self, index,   )
Dataset.__init__(self, X, y,   )
Dataset.__len__(self,   )
Dataset.pad_sequences(sequences,   )
Discriminator.__init__(self, class_size,  pretrained_model="gpt2-medium", cached_mode=False, device="cpu",  )
Discriminator.avg_representation(self, x,   )
Discriminator.forward(self, x,   )
Discriminator.get_classifier(self,   )
Discriminator.train_custom(self,   )

---------------functions---------------
cached_collate_fn(data,   )
collate_fn(data,   )
evaluate_performance(data_loader, discriminator,  device="cpu",  )
get_cached_data_loader(dataset, batch_size, discriminator,  shuffle=False, device="cpu",  )
predict(input_sentence, model, classes,  cached=False, device="cpu",  )
train_discriminator(dataset,  dataset_fp=None, pretrained_model="gpt2-medium", epochs=10, batch_size=64, log_interval=10, save_model=False, cached=False, no_cuda=False,  )
train_epoch(data_loader, discriminator, optimizer,  epoch=0, log_interval=10, device="cpu",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\pplm\pplm_transformer\__init__.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\vae\cli_generate_data.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\vae\network_test.py
----------------methods----------------
BetaVAE_H.__init__(self,  z_dim=10, nc=3,  )
BetaVAE_H._decode(self, z,   )
BetaVAE_H._encode(self, x,   )
BetaVAE_H.forward(self, x,   )
BetaVAE_H.weight_init(self,   )
BetaVAE_new.__init__(self,  z_dim=10, nc=3,  )
BetaVAE_new._decode(self, z,   )
BetaVAE_new._encode(self, x,   )
BetaVAE_new.forward(self, x,   )
BetaVAE_new.weight_init(self,   )
View.__init__(self, size,   )
View.forward(self, tensor,   )

---------------functions---------------
kaiming_init(m,   )
normal_init(m, mean, std,   )
reparametrize(mu, logvar,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\vae\util.py
----------------methods----------------

---------------functions---------------
create_sin_2d_array_cv(x, y,  resoltuion=data['resolution'], amp=data['amplitude'],  )
create_sin_2d_array_plt(x, y,  xmax=data['resolution'], ymax=data['resolution'], amp=data['amplitude'],  )
generate_random_cos( n_rand_starts=1, a=1, w=1, b=0, c=0, x_upbound=1, x_downbound=-1, step=0.2,  )
generate_random_sin( n_rand_starts=100, amplitude=1, n_pis=4, omega=1, step=0.2,  )
generate_train_img(folder,  N_type=1, amax=5, wmin=5, wmax=10, bmin=-2, bmax=2, cmin=-2, cmax=2, step=0.1, wfreq=0.5,  )
generate_train_img_cv(folder,  N_type=1, amax=5, wmin=5, wmax=10, bmin=-2, bmax=2, cmin=-2, cmax=2, step=0.1, wfreq=0.5,  )
generate_train_npz(folder,  N_type=1, amax=5, wmin=5, wmax=10, bmin=-2, bmax=2, cmin=-2, cmax=2, step=0.1, wfreq=0.5, resoltuion=data['resolution'],  )
generate_train_npz_cv(folder,  N_type=1, amax=5, wmin=5, wmax=10, bmin=-2, bmax=2, cmin=-2, cmax=2, step=0.1, wfreq=0.5, resoltuion=data['resolution'],  )
get_resolution(  )
plot_save_disk(x, y, filename,  xmax=data['resolution'], ymax=data['resolution'], amp=data['amplitude'],  )
plot_save_disk_cv(x, y, filename,  xmax=data['resolution'], ymax=data['resolution'], amp=data['amplitude'],  )
set_resolution( resolution=64,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\vae\__init__.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\vae\models\cli.py
----------------methods----------------

---------------functions---------------
load_argument(  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\vae\models\__init__.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\vae\models\Beta_VAE\dataset.py
----------------methods----------------
CustomImageFolder.__getitem__(self, index,   )
CustomImageFolder.__init__(self, root,  transform=None,  )
CustomTensorDataset.__getitem__(self, index,   )
CustomTensorDataset.__init__(self, data_tensor,   )
CustomTensorDataset.__len__(self,   )

---------------functions---------------
is_power_of_2(num,   )
return_data(args,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\vae\models\Beta_VAE\main.py
----------------methods----------------

---------------functions---------------
main(args,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\vae\models\Beta_VAE\model.py
----------------methods----------------
BetaVAE_B.__init__(self,  z_dim=10, nc=1,  )
BetaVAE_B._decode(self, z,   )
BetaVAE_B._encode(self, x,   )
BetaVAE_B.forward(self, x,   )
BetaVAE_B.weight_init(self,   )
BetaVAE_H.__init__(self,  z_dim=10, nc=3,  )
BetaVAE_H._decode(self, z,   )
BetaVAE_H._encode(self, x,   )
BetaVAE_H.forward(self, x,   )
BetaVAE_H.weight_init(self,   )
BetaVAE_H_4_nn.__init__(self,  z_dim=10, nc=3,  )
BetaVAE_H_4_nn._decode(self, z,   )
BetaVAE_H_4_nn._encode(self, x,   )
BetaVAE_H_4_nn.forward(self, x,   )
BetaVAE_H_4_nn.weight_init(self,   )
View.__init__(self, size,   )
View.forward(self, tensor,   )

---------------functions---------------
kaiming_init(m,   )
normal_init(m, mean, std,   )
reparametrize(mu, logvar,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\vae\models\Beta_VAE\solver.py
----------------methods----------------
DataGather.__init__(self,   )
DataGather.flush(self,   )
DataGather.get_empty_data_dict(self,   )
DataGather.insert(self,   **kwargs)
Solver.__init__(self, args,   )
Solver.load_checkpoint(self, filename,   )
Solver.net_mode(self, train,   )
Solver.save_checkpoint(self, filename,  silent=True,  )
Solver.train(self,   )
Solver.viz_lines(self,   )
Solver.viz_reconstruction(self,   )
Solver.viz_traverse(self,  limit=3, inter=2/3, loc=-1,  )

---------------functions---------------
kl_divergence(mu, logvar,   )
reconstruction_loss(x, x_recon, distribution,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\vae\models\Beta_VAE\utils.py
----------------methods----------------

---------------functions---------------
cuda(tensor, uses_cuda,   )
grid2gif(image_str, output_gif,  delay=100,  )
str2bool(v,   )
where(cond, x, y,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\vae\models\Beta_VAE\__init__.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\vae\models\Beta_VAE_fft\dataset.py
----------------methods----------------
CustomImageFolder.__getitem__(self, index,   )
CustomImageFolder.__init__(self, root,  transform=None,  )
CustomTensorDataset.__getitem__(self, index,   )
CustomTensorDataset.__init__(self, data_tensor,   )
CustomTensorDataset.__len__(self,   )

---------------functions---------------
is_power_of_2(num,   )
return_data(args,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\vae\models\Beta_VAE_fft\main.py
----------------methods----------------

---------------functions---------------
main(args,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\vae\models\Beta_VAE_fft\model.py
----------------methods----------------
BetaVAE_B.__init__(self,  z_dim=10, nc=1,  )
BetaVAE_B._decode(self, z,   )
BetaVAE_B._encode(self, x,   )
BetaVAE_B.forward(self, x,   )
BetaVAE_B.weight_init(self,   )
BetaVAE_H.__init__(self,  z_dim=10, nc=3,  )
BetaVAE_H._decode(self, z,   )
BetaVAE_H._encode(self, x,   )
BetaVAE_H.forward(self, x,   )
BetaVAE_H.weight_init(self,   )
BetaVAE_fft.__init__(self,  z_dim=10, nc=3,  )
BetaVAE_fft._decode(self, z,   )
BetaVAE_fft._encode(self, x,   )
BetaVAE_fft.forward(self, x,   )
BetaVAE_fft.weight_init(self,   )
View.__init__(self, size,   )
View.forward(self, tensor,   )

---------------functions---------------
kaiming_init(m,   )
normal_init(m, mean, std,   )
reparametrize(mu, logvar,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\vae\models\Beta_VAE_fft\solver.py
----------------methods----------------
DataGather.__init__(self,   )
DataGather.flush(self,   )
DataGather.get_empty_data_dict(self,   )
DataGather.insert(self,   **kwargs)
Solver.__init__(self, args,   )
Solver.load_checkpoint(self, filename,   )
Solver.net_mode(self, train,   )
Solver.save_checkpoint(self, filename,  silent=True,  )
Solver.train(self,   )
Solver.viz_lines(self,   )
Solver.viz_reconstruction(self,   )
Solver.viz_traverse(self,  limit=3, inter=2/3, loc=-1,  )

---------------functions---------------
kl_divergence(mu, logvar,   )
reconstruction_loss(x, x_recon, distribution,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\vae\models\Beta_VAE_fft\utils.py
----------------methods----------------

---------------functions---------------
cuda(tensor, uses_cuda,   )
grid2gif(image_str, output_gif,  delay=100,  )
str2bool(v,   )
where(cond, x, y,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tch\vae\models\Beta_VAE_fft\__init__.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\10_encoder_vanilla.py
----------------methods----------------
Model.__init__(self, learning_rate, num_layers, size, size_layer, output_size,  forget_bias=0.1, epoch=500, timestep=5,  )
Model.anchor(signal, weight,   )
Model.build_model(self,   )

---------------functions---------------
fit(model, data_frame,   )
predict(model, sess, data_frame,   )
reducedimension(input_,  dimension=2, learning_rate=0.01, hidden_layer=256, epoch=20,  )
test( filename="dataset/GOOG-year.csv",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\11_bidirectional_vanilla.py
----------------methods----------------
Model.__init__(self, learning_rate, num_layers, size, size_layer, output_size,  forget_bias=0.1, epoch=500, timestep=5,  )
Model.anchor(signal, weight,   )

---------------functions---------------
fit(model, data_frame,   )
predict(model, sess, data_frame,  get_hidden_state=False, init_value_forward=None, init_value_backward=None,  )
test( filename="dataset/GOOG-year.csv",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\12_vanilla_2path.py
----------------methods----------------
Model.__init__(self, learning_rate, num_layers, size, size_layer, output_size,  forget_bias=0.1, epoch=500, timestep=5,  )
Model.anchor(signal, weight,   )

---------------functions---------------
fit(model, data_frame,   )
predict(model, sess, data_frame,  get_hidden_state=False, init_value_forward=None, init_value_backward=None,  )
test( filename="dataset/GOOG-year.csv",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\13_lstm_seq2seq.py
----------------methods----------------
Model.__init__(self, learning_rate, num_layers, size, size_layer, output_size,  forget_bias=0.1, epoch=500, timestep=5,  )
Model.anchor(signal, weight,   )

---------------functions---------------
fit(model, data_frame,   )
predict(model, sess, data_frame,  get_hidden_state=False, init_value=None,  )
test( filename="dataset/GOOG-year.csv",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\14_lstm_attention.py
----------------methods----------------
Model.__init__(self, learning_rate, num_layers, size, size_layer, output_size,  forget_bias=0.1, attention_size=10, epoch=500, timestep=5,  )
Model.anchor(signal, weight,   )

---------------functions---------------
fit(model, data_frame,   )
predict(model, sess, data_frame,  get_hidden_state=False, init_value=None,  )
test( filename="dataset/GOOG-year.csv",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\15_lstm_seq2seq_attention.py
----------------methods----------------
Model.__init__(self, learning_rate, num_layers, size, size_layer, output_size,  forget_bias=0.1, attention_size=10, epoch=500, timestep=5,  )
Model.anchor(signal, weight,   )

---------------functions---------------
fit(model, data_frame,   )
predict(model, sess, data_frame,  get_hidden_state=False, init_value=None,  )
test( filename="dataset/GOOG-year.csv",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\16_lstm_seq2seq_bidirectional.py
----------------methods----------------
Model.__init__(self, learning_rate, num_layers, size, size_layer, output_size,  forget_bias=0.1, epoch=500, timestep=5,  )
Model.anchor(signal, weight,   )

---------------functions---------------
fit(model, data_frame,   )
predict(model, sess, data_frame,  get_hidden_state=False, init_value_forward=None, init_value_backward=None,  )
test( filename="dataset/GOOG-year.csv",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\17_lstm_seq2seq_bidirectional_attention.py
----------------methods----------------
Model.__init__(self, learning_rate, num_layers, size, size_layer, output_size,  forget_bias=0.1, attention_size=10, epoch=500, timestep=5,  )
Model.anchor(signal, weight,   )

---------------functions---------------
fit(model, data_frame,   )
predict(model, sess, data_frame,  get_hidden_state=False, init_value_forward=None, init_value_backward=None,  )
test( filename="dataset/GOOG-year.csv",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\18_lstm_attention_scaleddot.py
----------------methods----------------
Model.__init__(self, learning_rate, num_layers, size, size_layer, output_size, seq_len,  forget_bias=0.1, epoch=500,  )
Model.anchor(signal, weight,   )

---------------functions---------------
fit(model, data_frame,   )
predict(model, sess, data_frame,  get_hidden_state=False, init_value=None,  )
test( filename="dataset/GOOG-year.csv",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\19_lstm_dilated.py
----------------methods----------------
Model.__init__(self, steps, dimension_input, dimension_output,  learning_rate=0.001, hidden_structs=[20], dilations=[1, 1, 1, 1], epoch=500,  )
Model.anchor(signal, weight,   )

---------------functions---------------
contruct_cells(hidden_structs,   )
dilated_rnn(cell, inputs, rate, states,  scope="default",  )
fit(model, data_frame,   )
multi_dilated_rnn(cells, inputs, dilations, states,   )
predict(model, sess, data_frame,  get_hidden_state=False, init_value=None,  )
rnn_reformat(x, input_dims, n_steps,   )
test( filename="dataset/GOOG-year.csv",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\1_lstm.py
----------------methods----------------
Model.__init__(self,  model_pars=None, data_pars=None, compute_pars=None,  **kwargs)

---------------functions---------------
fit(model,  data_pars=None, compute_pars=None, out_pars=None,  **kwarg)
fit_metrics(model,  sess=None, data_pars=None, compute_pars=None, out_pars=None,  )
get_dataset( data_pars=None,  )
get_params( param_pars={},  **kw)
load( load_pars=None,  )
metrics(model,  sess=None, data_pars=None, compute_pars=None, out_pars=None,  )
predict(model,  sess=None, data_pars=None, compute_pars=None, out_pars=None, get_hidden_state=False, init_value=None,  )
reset_model(  )
save(model,  session=None, save_pars=None,  )
test( data_path="dataset/", pars_choice="test01", config_mode="test",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\20_only_attention.py
----------------methods----------------
Model.__init__(self, seq_len, learning_rate, dimension_input, dimension_output,  epoch=100,  )
Model.anchor(signal, weight,   )

---------------functions---------------
fit(model, data_frame,   )
predict(model, sess, data_frame,   )
sinusoidal_positional_encoding(inputs, num_units,  zero_pad=False, scale=False,  )
test( filename="dataset/GOOG-year.csv",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\21_multihead_attention.py
----------------methods----------------
Model.__init__(self, dimension_input, dimension_output, seq_len, learning_rate,  num_heads=8, attn_windows=range(1, 6), epoch=1,  )
Model.anchor(signal, weight,   )
Model.multihead_attn(self, inputs, masks,   )
Model.window_mask(self, h_w,   )

---------------functions---------------
embed_seq(inputs,  vocab_size=None, embed_dim=None, zero_pad=False, scale=False,  )
fit(model, data_frame,   )
layer_norm(inputs,  epsilon=1e-8,  )
learned_positional_encoding(inputs, embed_dim,  zero_pad=False, scale=False,  )
pointwise_feedforward(inputs,  num_units=[None, None], activation=None,  )
predict(model, sess, data_frame,   )
test( filename="dataset/GOOG-year.csv",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\22_lstm_bahdanau.py
----------------methods----------------
Model.__init__(self, learning_rate, num_layers, size, size_layer, output_size,  forget_bias=0.1, attention_size=10, epoch=100, timestep=5,  )
Model.anchor(signal, weight,   )

---------------functions---------------
fit(model, data_frame,   )
predict(model, sess, data_frame,  get_hidden_state=False, init_value=None,  )
test( filename="dataset/GOOG-year.csv",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\23_lstm_luong.py
----------------methods----------------
Model.__init__(self, learning_rate, num_layers, size, size_layer, output_size,  forget_bias=0.1, attention_size=10, epoch=100, timestep=5,  )
Model.anchor(signal, weight,   )

---------------functions---------------
fit(model, data_frame,   )
predict(model, sess, data_frame,  get_hidden_state=False, init_value=None,  )
test( filename="dataset/GOOG-year.csv",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\24_lstm_luong_bahdanau.py
----------------methods----------------
Model.__init__(self, learning_rate, num_layers, size, size_layer, output_size,  forget_bias=0.1, attention_size=10, epoch=1, timestep=5,  )
Model.anchor(signal, weight,   )

---------------functions---------------
fit(model, data_frame,   )
predict(model, sess, data_frame,  get_hidden_state=False, init_value=None,  )
test( filename="dataset/GOOG-year.csv",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\25_dnc.py
----------------methods----------------
Model.__init__(self, learning_rate, size, size_layer, output_size, epoch, timestep, access_config, controller_config, clip_value,   )

---------------functions---------------
fit(model, data_frame,   )
predict(model, sess, data_frame,  get_hidden_state=False, init_value=None,  )
test( filename="dataset/GOOG-year.csv",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\26_lstm_residual.py
----------------methods----------------
Model.__init__(self, learning_rate, num_layers, size, size_layer, output_size,  epoch=1, timestep=5,  )
Model.anchor(signal, weight,   )

---------------functions---------------
fit(model, data_frame,   )
predict(model, sess, data_frame,  get_hidden_state=False, init_value=None,  )
test( filename="dataset/GOOG-year.csv",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\27_byte_net.py
----------------methods----------------
Model.__init__(self, size, output_size, channels, encoder_dilations, encoder_filter_width,  learning_rate=0.001, beta1=0.5, epoch=1, timestep=5,  )
Model.anchor(signal, weight,   )

---------------functions---------------
bytenet_residual_block(input_, dilation, layer_no, residual_channels, filter_width,  causal=True,  )
conv1d(input_, output_channels,  dilation=1, filter_width=1, causal=False,  )
fit(model, data_frame,   )
layer_normalization(x,  epsilon=1e-8,  )
predict(model, sess, data_frame,   )
test( filename="dataset/GOOG-year.csv",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\28_attention_is_all_you_need.py
----------------methods----------------
Model.__init__(self, size_layer, embedded_size, learning_rate, size, output_size,  num_blocks=2, num_heads=8, min_freq=50, epoch=1, timestep=5,  )
Model.anchor(signal, weight,   )

---------------functions---------------
fit(model, data_frame,   )
label_smoothing(inputs,  epsilon=0.1,  )
layer_norm(inputs,  epsilon=1e-8,  )
learned_position_encoding(inputs, mask, embed_dim,   )
multihead_attn(queries, keys, q_masks, k_masks, future_binding, num_units, num_heads,   )
pointwise_feedforward(inputs, hidden_units,  activation=None,  )
predict(model, sess, data_frame,   )
sinusoidal_position_encoding(inputs, mask, repr_dim,   )
test( filename="dataset/GOOG-year.csv",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\29_fairseq.py
----------------methods----------------
Model.__init__(self, n_layers, size, output_size, emb_size, n_hidden, n_attn_heads, learning_rate,  epoch=1, timestep=5,  )
Model.anchor(signal, weight,   )

---------------functions---------------
decoder_block(inp, n_hidden, filter_size,   )
encoder_block(inp, n_hidden, filter_size,   )
fit(model, data_frame,   )
glu(x,   )
layer(inp, conv_block, kernel_width, n_hidden,  residual=None,  )
predict(model, sess, data_frame,   )
test( filename="dataset/GOOG-year.csv",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\2_encoder_lstm.py
----------------methods----------------
Model.__init__(self, learning_rate, num_layers, size, size_layer, output_size,  forget_bias=0.1, epoch=5, timestep=5,  )
Model.anchor(signal, weight,   )
Model.build_model(self,   )

---------------functions---------------
fit(model, data_frame,   )
predict(model, sess, data_frame,   )
reducedimension(input_,  dimension=2, learning_rate=0.01, hidden_layer=256, epoch=20, sess=None,  )
test( filename="dataset/GOOG-year.csv",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\3_bidirectional_lstm.py
----------------methods----------------
Model.__init__(self, learning_rate, num_layers, size, size_layer, output_size,  forget_bias=0.1, epoch=500, timestep=5,  )
Model.anchor(signal, weight,   )

---------------functions---------------
fit(model, data_frame,   )
predict(model, sess, data_frame,  get_hidden_state=False, init_value_forward=None, init_value_backward=None,  )
test( filename="dataset/GOOG-year.csv",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\4_lstm_2path.py
----------------methods----------------
Model.__init__(self, learning_rate, num_layers, size, size_layer, output_size,  forget_bias=0.1, timestep=5, epoch=10,  )
Model.anchor(signal, weight,   )

---------------functions---------------
fit(model, data_frame,   )
predict(model, sess, data_frame,  get_hidden_state=False, init_value_forward=None, init_value_backward=None,  )
test( filename="dataset/GOOG-year.csv",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\50lstm attention.py
----------------methods----------------
AttentionModel.__init__(self, x, y, layer_1_rnn_units,  attn_dense_nodes=0, epochs=100, batch_size=128, shared_attention_layer=True, chg_yield=False, float_type='float32', regularization=(0.00001, '00001'), window=52, predict=1,  )
AttentionModel.build_attention_rnn(self,   )
AttentionModel.calculate_attentions(self, x_data,   )
AttentionModel.delete_model(self,   )
AttentionModel.fit_model(self,   )
AttentionModel.heatmap(self, data,  title_supplement=None,  )
AttentionModel.load_model(self,   )
AttentionModel.make_shared_layers(self,   )
AttentionModel.save_model(self,   )
AttentionModel.set_learning(self, learning,   )

---------------functions---------------
softmax_activation(x,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\5_gru.py
----------------methods----------------
Model.__init__(self, learning_rate, num_layers, size, size_layer, output_size,  forget_bias=0.1, epoch=1, timestep=5,  )
Model.anchor(signal, weight,   )

---------------functions---------------
fit(model, data_frame,   )
predict(model, sess, data_frame,  get_hidden_state=False, init_value=None,  )
test( filename="dataset/GOOG-year.csv",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\6_encoder_gru.py
----------------methods----------------
Model.__init__(self, learning_rate, num_layers, size, size_layer, output_size,  forget_bias=0.1, timestep=5, epoch=1,  )
Model.anchor(signal, weight,   )
Model.build_model(self,   )

---------------functions---------------
fit(model, data_frame,   )
predict(model, sess, data_frame,   )
reducedimension(input_,  dimension=2, learning_rate=0.01, hidden_layer=256, epoch=20,  )
test( filename="dataset/GOOG-year.csv",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\7_bidirectional_gru.py
----------------methods----------------
Model.__init__(self, learning_rate, num_layers, size, size_layer, output_size,  forget_bias=0.1, epoch=500, timestep=5,  )
Model.anchor(signal, weight,   )

---------------functions---------------
fit(model, data_frame,   )
predict(model, sess, data_frame,  get_hidden_state=False, init_value_forward=None, init_value_backward=None,  )
test( filename="dataset/GOOG-year.csv",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\8_gru_2path.py
----------------methods----------------
Model.__init__(self, learning_rate, num_layers, size, size_layer, output_size,  forget_bias=0.1, epoch=500, timestep=5,  )
Model.anchor(signal, weight,   )

---------------functions---------------
fit(model, data_frame,   )
predict(model, sess, data_frame,  get_hidden_state=False, init_value_forward=None, init_value_backward=None,  )
test( filename="dataset/GOOG-year.csv",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\9_vanilla.py
----------------methods----------------
Model.__init__(self, learning_rate, num_layers, size, size_layer, output_size,  forget_bias=0.1, epoch=500, timestep=5,  )
Model.anchor(signal, weight,   )

---------------functions---------------
fit(model, data_frame,   )
predict(model, sess, data_frame,  get_hidden_state=False, init_value=None,  )
test( filename="dataset/GOOG-year.csv",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\access.py
----------------methods----------------
MemoryAccess.__init__(self,  memory_size=128, word_size=20, num_reads=1, num_writes=1, name="memory_access",  )
MemoryAccess._build(self, inputs, prev_state,   )
MemoryAccess._read_inputs(self, inputs,   )
MemoryAccess._read_weights(self, inputs, memory, prev_read_weights, link,   )
MemoryAccess._write_weights(self, inputs, memory, usage,   )
MemoryAccess.output_size(self,   )
MemoryAccess.state_size(self,   )

---------------functions---------------
_erase_and_write(memory, address, reset_weights, values,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\addressing.py
----------------methods----------------
CosineWeights.__init__(self, num_heads, word_size,  strength_op=tf.nn.softplus, name="cosine_weights",  )
CosineWeights._build(self, memory, keys, strengths,   )
Freeness.__init__(self, memory_size,  name="freeness",  )
Freeness._allocation(self, usage,   )
Freeness._build(self, write_weights, free_gate, read_weights, prev_usage,   )
Freeness._usage_after_read(self, prev_usage, free_gate, read_weights,   )
Freeness._usage_after_write(self, prev_usage, write_weights,   )
Freeness.state_size(self,   )
Freeness.write_allocation_weights(self, usage, write_gates, num_writes,   )
TemporalLinkage.__init__(self, memory_size, num_writes,  name="temporal_linkage",  )
TemporalLinkage._build(self, write_weights, prev_state,   )
TemporalLinkage._link(self, prev_link, prev_precedence_weights, write_weights,   )
TemporalLinkage._precedence_weights(self, prev_precedence_weights, write_weights,   )
TemporalLinkage.directional_read_weights(self, link, prev_read_weights, forward,   )
TemporalLinkage.state_size(self,   )

---------------functions---------------
_vector_norms(m,   )
weighted_softmax(activations, strengths, strengths_op,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\autoencoder.py
----------------methods----------------

---------------functions---------------
reducedimension(input_,  dimension=2, learning_rate=0.01, hidden_layer=256, epoch=20,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\dnc.py
----------------methods----------------
DNC.__init__(self, access_config, controller_config, output_size,  clip_value=None, name="dnc",  )
DNC._build(self, inputs, prev_state,   )
DNC._clip_if_enabled(self, x,   )
DNC.initial_state(self, batch_size,  dtype=tf.float32,  )
DNC.output_size(self,   )
DNC.state_size(self,   )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\util.py
----------------methods----------------

---------------functions---------------
batch_gather(values, indices,   )
batch_invert_permutation(permutations,   )
one_hot(length, index,   )
os_file_path(data_path,   )
os_module_path(  )
os_package_root_path(filepath,  sublevel=0, path_add="",  )
set_root_dir(  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\__init__.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\deepar\settings.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\deepar\__init__.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\deepar\dataset\time_series.py
----------------methods----------------
MockTs.__init__(self,  t_min=0, t_max=30, resolution=.1,  )
MockTs._time_series(t,   )
MockTs.generate_test_data(self, n_steps,   )
MockTs.mock_ts(self,   )
MockTs.next_batch(self, batch_size, n_steps,   )
TimeSeries.__init__(self, pandas_df,  one_hot_root_list=None, grouping_variable='category', scaler=None,  )
TimeSeries._one_hot_padding(self, pandas_df, padding_df,   )
TimeSeries._pad_ts(self, pandas_df, desired_len,  padding_val=0,  )
TimeSeries._sample_ts(pandas_df, desired_len,   )
TimeSeries.next_batch(self, batch_size, n_steps,  target_var='target', verbose=False, padding_value=0,  )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\deepar\dataset\__init__.py
----------------methods----------------
Dataset.__init__(self,   )
Dataset.next_batch(self,   **kwargs)

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\deepar\model\layers.py
----------------methods----------------
GaussianLayer.__init__(self, output_dim,   **kwargs)
GaussianLayer.build(self, input_shape,   )
GaussianLayer.call(self, x,   )
GaussianLayer.compute_output_shape(self, input_shape,   )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\deepar\model\loss.py
----------------methods----------------

---------------functions---------------
gaussian_likelihood(sigma,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\deepar\model\lstm.py
----------------methods----------------
DeepAR.__init__(self, ts_obj,  steps_per_epoch=50, epochs=100, loss=gaussian_likelihood, optimizer='adam', with_custom_nn_structure=None,  )
DeepAR.basic_structure(  )
DeepAR.instantiate_and_fit(self,  verbose=False,  )
DeepAR.model(self,   )
DeepAR.predict_theta_from_input(self, input_list,   )

---------------functions---------------
ts_generator(ts_obj, n_steps,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\deepar\model\__init__.py
----------------methods----------------
NNModel.__init__(self,   )
NNModel.instantiate_and_fit(self,   **kwargs)
NNModel.net_structure(self,   **kwargs)

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\deepar\utils\__init__.py
----------------methods----------------

---------------functions---------------
clear_keras_session(  )
set_seed_and_reset_graph( seed=42,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\rl\0_template_rl.py
----------------methods----------------
Agent.__init__(self, history, do_action,  params={},  )
Agent.discount_rewards(self, r,   )
Agent.get_predicted_action(self, sequence,   )
Agent.get_state(self, t,  state=None, history=None, reward=None,  )
Agent.predict_action(self, inputs,   )
Agent.run_sequence(self, history, do_action, params,   )
Agent.train(self,  n_iters=1, n_log_freq=1, state_initial=None, reward_initial=None,  )
Model.__init__(self, history,  params={},  )

---------------functions---------------
do_action_example(action_dict,   )
fit(model, df, do_action,  state_initial=None, reward_initial=None, params=None,  )
predict(model, sess, df,  do_action=None, params=params,  )
val(x, y,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\rl\1.turtle-agent.py
----------------methods----------------

---------------functions---------------
buy_stock(real_movement, signal,  initial_money=10000, max_buy=20, max_sell=20,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\rl\10.duel-q-learning-agent.py
----------------methods----------------
Agent.__init__(self, state_size, window_size, trend, skip, batch_size,   )
Agent.act(self, state,   )
Agent.buy(self, initial_money,   )
Agent.get_state(self, t,   )
Agent.replay(self, batch_size,   )
Agent.train(self, iterations, checkpoint, initial_money,   )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\rl\11.double-duel-q-learning-agent.py
----------------methods----------------
Agent.__init__(self, state_size, window_size, trend, skip,   )
Agent._assign(self,   )
Agent._construct_memories(self, replay,   )
Agent._memorize(self, state, action, reward, new_state, done,   )
Agent._select_action(self, state,   )
Agent.buy(self, initial_money,   )
Agent.get_predicted_action(self, sequence,   )
Agent.get_state(self, t,   )
Agent.predict(self, inputs,   )
Agent.train(self, iterations, checkpoint, initial_money,   )
Model.__init__(self, input_size, output_size, layer_size, learning_rate,   )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\rl\12.duel-recurrent-q-learning-agent.py
----------------methods----------------
Agent.__init__(self, state_size, window_size, trend, skip,   )
Agent._construct_memories(self, replay,   )
Agent._memorize(self, state, action, reward, new_state, dead, rnn_state,   )
Agent.buy(self, initial_money,   )
Agent.get_state(self, t,   )
Agent.train(self, iterations, checkpoint, initial_money,   )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\rl\13.double-duel-recurrent-q-learning-agent.py
----------------methods----------------
Agent.__init__(self, state_size, window_size, trend, skip,   )
Agent._assign(self, from_name, to_name,   )
Agent._construct_memories(self, replay,   )
Agent._memorize(self, state, action, reward, new_state, dead, rnn_state,   )
Agent._select_action(self, state,   )
Agent.buy(self, initial_money,   )
Agent.get_state(self, t,   )
Agent.train(self, iterations, checkpoint, initial_money,   )
Model.__init__(self, input_size, output_size, layer_size, learning_rate, name,   )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\rl\14.actor-critic-agent.py
----------------methods----------------
Actor.__init__(self, name, input_size, output_size, size_layer,   )
Agent.__init__(self, state_size, window_size, trend, skip,   )
Agent._assign(self, from_name, to_name,   )
Agent._construct_memories_and_train(self, replay,   )
Agent._memorize(self, state, action, reward, new_state, dead,   )
Agent._select_action(self, state,   )
Agent.buy(self, initial_money,   )
Agent.get_state(self, t,   )
Agent.train(self, iterations, checkpoint, initial_money,   )
Critic.__init__(self, name, input_size, output_size, size_layer, learning_rate,   )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\rl\15.actor-critic-duel-agent.py
----------------methods----------------
Actor.__init__(self, name, input_size, output_size, size_layer,   )
Agent.__init__(self, state_size, window_size, trend, skip,   )
Agent._assign(self, from_name, to_name,   )
Agent._construct_memories_and_train(self, replay,   )
Agent._memorize(self, state, action, reward, new_state, dead,   )
Agent._select_action(self, state,   )
Agent.buy(self, initial_money,   )
Agent.get_state(self, t,   )
Agent.train(self, iterations, checkpoint, initial_money,   )
Critic.__init__(self, name, input_size, output_size, size_layer, learning_rate,   )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\rl\16.actor-critic-recurrent-agent.py
----------------methods----------------
Actor.__init__(self, name, input_size, output_size, size_layer,   )
Agent.__init__(self, state_size, window_size, trend, skip,   )
Agent._assign(self, from_name, to_name,   )
Agent._construct_memories_and_train(self, replay,   )
Agent._memorize(self, state, action, reward, new_state, dead, rnn_state,   )
Agent._select_action(self, state,   )
Agent.buy(self, initial_money,   )
Agent.get_state(self, t,   )
Agent.train(self, iterations, checkpoint, initial_money,   )
Critic.__init__(self, name, input_size, output_size, size_layer, learning_rate,   )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\rl\17.actor-critic-duel-recurrent-agent.py
----------------methods----------------
Actor.__init__(self, name, input_size, output_size, size_layer,   )
Agent.__init__(self, state_size, window_size, trend, skip,   )
Agent._assign(self, from_name, to_name,   )
Agent._construct_memories_and_train(self, replay,   )
Agent._memorize(self, state, action, reward, new_state, dead, rnn_state,   )
Agent._select_action(self, state,   )
Agent.buy(self, initial_money,   )
Agent.get_state(self, t,   )
Agent.train(self, iterations, checkpoint, initial_money,   )
Critic.__init__(self, name, input_size, output_size, size_layer, learning_rate,   )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\rl\18.curiosity-q-learning-agent.py
----------------methods----------------
Agent.__init__(self, state_size, window_size, trend, skip,   )
Agent._construct_memories(self, replay,   )
Agent._memorize(self, state, action, reward, new_state, done,   )
Agent._select_action(self, state,   )
Agent.buy(self, initial_money,   )
Agent.get_predicted_action(self, sequence,   )
Agent.get_state(self, t,   )
Agent.predict(self, inputs,   )
Agent.train(self, iterations, checkpoint, initial_money,   )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\rl\19.recurrent-curiosity-q-learning-agent.py
----------------methods----------------
Agent.__init__(self, state_size, window_size, trend, skip,   )
Agent._construct_memories(self, replay,   )
Agent._memorize(self, state, action, reward, new_state, done, rnn_state,   )
Agent.buy(self, initial_money,   )
Agent.get_state(self, t,   )
Agent.train(self, iterations, checkpoint, initial_money,   )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\rl\2.moving-average-agent.py
----------------methods----------------

---------------functions---------------
buy_stock(real_movement, signal,  initial_money=10000, max_buy=20, max_sell=20,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\rl\20.duel-curiosity-q-learning-agent.py
----------------methods----------------
Agent.__init__(self, state_size, window_size, trend, skip,   )
Agent._construct_memories(self, replay,   )
Agent._memorize(self, state, action, reward, new_state, done,   )
Agent._select_action(self, state,   )
Agent.buy(self, initial_money,   )
Agent.get_predicted_action(self, sequence,   )
Agent.get_state(self, t,   )
Agent.predict(self, inputs,   )
Agent.train(self, iterations, checkpoint, initial_money,   )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\rl\21.neuro-evolution-agent.py
----------------methods----------------
NeuroEvolution.__init__(self, population_size, mutation_rate, model_generator, state_size, window_size, trend, skip, initial_money,   )
NeuroEvolution._initialize_population(self,   )
NeuroEvolution.act(self, p, state,   )
NeuroEvolution.buy(self, individual,   )
NeuroEvolution.calculate_fitness(self,   )
NeuroEvolution.crossover(self, parent1, parent2,   )
NeuroEvolution.evolve(self,  generations=20, checkpoint=5,  )
NeuroEvolution.get_state(self, t,   )
NeuroEvolution.inherit_weights(self, parent, child,   )
NeuroEvolution.mutate(self, individual,  scale=1.0,  )
neuralnetwork.__init__(self, id_,  hidden_size=128,  )

---------------functions---------------
feed_forward(X, nets,   )
relu(X,   )
softmax(X,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\rl\22.neuro-evolution-novelty-search-agent.py
----------------methods----------------
NeuroEvolution.__init__(self, population_size, mutation_rate, model_generator, state_size, window_size, trend, skip, initial_money,   )
NeuroEvolution._initialize_population(self,   )
NeuroEvolution._memorize(self, q, i, limit,   )
NeuroEvolution.act(self, p, state,   )
NeuroEvolution.buy(self, individual,   )
NeuroEvolution.calculate_fitness(self,   )
NeuroEvolution.crossover(self, parent1, parent2,   )
NeuroEvolution.evaluate(self, individual, backlog, pop,  k=4,  )
NeuroEvolution.evolve(self,  generations=20, checkpoint=5,  )
NeuroEvolution.get_state(self, t,   )
NeuroEvolution.inherit_weights(self, parent, child,   )
NeuroEvolution.mutate(self, individual,  scale=1.0,  )
neuralnetwork.__init__(self, id_,  hidden_size=128,  )

---------------functions---------------
feed_forward(X, nets,   )
relu(X,   )
softmax(X,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\rl\3.signal-rolling-agent.py
----------------methods----------------

---------------functions---------------
buy_stock(real_movement,  delay=5, initial_state=1, initial_money=10000, max_buy=20, max_sell=20,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\rl\4.policy-gradient-agent_old.py
----------------methods----------------
Agent.__init__(self, state_size, window_size, trend, skip,   )
Agent.buy(self, initial_money,   )
Agent.discount_rewards(self, r,   )
Agent.get_predicted_action(self, sequence,   )
Agent.get_state(self, t,  reward_state=None,  )
Agent.predict(self, inputs,   )
Agent.predict_sequence(self, trend_input, do_action,  param=None,  )
Agent.train(self, iterations, checkpoint, initial_money,   )
Model.__init__(self, state_size, window_size, trend, skip, iterations, initial_reward,   )

---------------functions---------------
do_action_example(action_dict,   )
fit(model, df, do_action,   )
predict(model, sess, df, do_action,   )
test( filename='dataset/GOOG-year.csv',  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\rl\4_policy-gradient-agent.py
----------------methods----------------
Agent.__init__(self, state_size, window_size, trend, skip,   )
Agent.discount_rewards(self, r,   )
Agent.get_predicted_action(self, sequence,   )
Agent.get_state(self, t,  reward_state=None,  )
Agent.predict(self, inputs,   )
Agent.predict_sequence(self, pars,  trend_history=None,  )
Agent.train(self, iterations, checkpoint, initial_money,   )
Model.__init__(self, state_size, window_size, trend, skip, iterations, initial_reward,  checkpoint=10,  )

---------------functions---------------
fit(model, dftrain,  params={},  )
predict(model, sess, dftest,  params={},  )
test( filename='dataset/GOOG-year.csv',  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\rl\5_q-learning-agent.py
----------------methods----------------
Agent.__init__(self, state_size, window_size, trend, skip, batch_size,   )
Agent.act(self, state,   )
Agent.get_state(self, t,   )
Agent.predict_sequence(self, pars,  trend_history=None,  )
Agent.replay(self, batch_size,   )
Agent.train(self, iterations, checkpoint, initial_money,   )
Model.__init__(self, state_size, window_size, trend, skip, iterations, initial_reward,  checkpoint=10,  )

---------------functions---------------
fit(model, dftrain,  params={},  )
predict(model, sess, dftest,  params={},  )
test( filename='../dataset/GOOG-year.csv',  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\rl\6_evolution-strategy-agent.py
----------------methods----------------
Agent.__init__(self, model, window_size, trend, skip, initial_money,   )
Agent.act(self, sequence,   )
Agent.fit(self, iterations, checkpoint,   )
Agent.get_reward(self, weights,   )
Agent.get_state(self, t,   )
Agent.run_sequence(self, df_test,   )
Deep_Evolution_Strategy.__init__(self, weights, reward_function, population_size, sigma, learning_rate,   )
Deep_Evolution_Strategy._get_weight_from_population(self, weights, population,   )
Deep_Evolution_Strategy.get_weights(self,   )
Deep_Evolution_Strategy.train(self,  epoch=100, print_every=1,  )
Model.__init__(self, input_size, layer_size, output_size, window_size, skip, initial_money,  iterations=500, checkpoint=10,  )
Model.get_weights(self,   )
Model.predict(self, inputs,   )
Model.set_weights(self, weights,   )

---------------functions---------------
fit(model, dftrain,  params={},  )
get_imports(  )
predict(model, sess, dftest,  params={},  )
test( filename='../dataset/GOOG-year.csv',  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\rl\7.double-q-learning-agent.py
----------------methods----------------
Agent.__init__(self, state_size, window_size, trend, skip,   )
Agent._assign(self,   )
Agent._construct_memories(self, replay,   )
Agent._memorize(self, state, action, reward, new_state, done,   )
Agent._select_action(self, state,   )
Agent.get_predicted_action(self, sequence,   )
Agent.get_state(self, t,   )
Agent.predict(self, inputs,   )
Agent.run_sequence(self, initial_money,   )
Agent.train(self, iterations, checkpoint, initial_money,   )
Model.__init__(self, window_size, trend, skip, iterations, initial_reward,  checkpoint=10,  )
QModel.__init__(self, input_size, output_size, layer_size, learning_rate,   )

---------------functions---------------
fit(model, dftrain,  params={},  )
predict(model, sess, dftest,  params={},  )
test( filename='../dataset/GOOG-year.csv',  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\rl\8.recurrent-q-learning-agent.py
----------------methods----------------
Agent.__init__(self, state_size, window_size, trend, skip,   )
Agent._construct_memories(self, replay,   )
Agent._memorize(self, state, action, reward, new_state, dead, rnn_state,   )
Agent.buy(self, initial_money,   )
Agent.get_state(self, t,   )
Agent.train(self, iterations, checkpoint, initial_money,   )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\rl\9.double-recurrent-q-learning-agent.py
----------------methods----------------
Agent.__init__(self, state_size, window_size, trend, skip,   )
Agent._assign(self, from_name, to_name,   )
Agent._construct_memories(self, replay,   )
Agent._memorize(self, state, action, reward, new_state, dead, rnn_state,   )
Agent._select_action(self, state,   )
Agent.buy(self, initial_money,   )
Agent.get_state(self, t,   )
Agent.train(self, iterations, checkpoint, initial_money,   )
Model.__init__(self, input_size, output_size, layer_size, learning_rate, name,   )

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\rl\updated-NES-google.py
----------------methods----------------
Agent.__init__(self, model, money, max_buy, max_sell, close, window_size, skip,   )
Agent.act(self, sequence,   )
Agent.buy(self,   )
Agent.fit(self, iterations, checkpoint,   )
Agent.get_reward(self, weights,   )
Deep_Evolution_Strategy.__init__(self, weights, reward_function, population_size, sigma, learning_rate,   )
Deep_Evolution_Strategy._get_weight_from_population(self, weights, population,   )
Deep_Evolution_Strategy.get_weights(self,   )
Deep_Evolution_Strategy.train(self,  epoch=100, print_every=1,  )
Model.__init__(self, input_size, layer_size, output_size,   )
Model.get_weights(self,   )
Model.predict(self, inputs,   )
Model.set_weights(self, weights,   )

---------------functions---------------
act(model, sequence,   )
f(w,   )
get_state(data, t, n,   )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\model_tf\rl\__init__.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\preprocess\__init__.py
----------------methods----------------

---------------functions---------------


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\template\00_template_keras.py
----------------methods----------------
Model.__init__(self,  model_pars=None, data_pars=None, compute_pars=None,  **kwargs)
Model_empty.__init__(self,  model_pars=None, compute_pars=None,  )

---------------functions---------------
_preprocess_XXXX(df,   **kw)
fit(model,  session=None, data_pars=None, model_pars=None, compute_pars=None, out_pars=None,  **kwargs)
get_dataset(  **kw)
get_params( choice=0, data_path="dataset/",  **kw)
load(path,   )
log( n=0, m=1,  *s)
metrics(ypred, data_pars,  compute_pars=None, out_pars=None,  **kwargs)
os_package_root_path(filepath,  sublevel=0, path_add="",  )
path_setup( out_folder="", sublevel=0, data_path="dataset/",  )
predict(model, data_pars,  compute_pars=None, out_pars=None,  **kwargs)
reset_model(  )
save(model, path,   )
test( data_path="dataset/", pars_choice=0,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\template\model_xxx.py
----------------methods----------------

---------------functions---------------
fit(model,  data_pars=None, compute_pars=None, out_pars=None,  **kw)
fit_metrics(model,  data_pars=None, compute_pars=None, out_pars=None,  **kw)
get_dataset( data_pars=None,  **kw)
get_params( param_pars={},  **kw)
load( load_pars={},  )
predict(model,  sess=None, data_pars=None, compute_pars=None, out_pars=None,  **kw)
reset_model(  )
save( model=None, session=None, save_pars={},  )
test( data_path="dataset/", pars_choice="json", config_mode="test",  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\template\zarchive\gluonts_model.py
----------------methods----------------
Model.__init__(self,  model_pars=None, compute_pars=None,  )

---------------functions---------------
get_params( choice=0, data_path="dataset/",  **kw)
test( data_path="dataset/",  )
test2( data_path="dataset/", out_path="GLUON/gluon.png", reset=True,  )


D:\_devs\Python01\gitdev\mlmodels\build\lib\mlmodels\template\zarchive\model_tf_sequential.py
----------------methods----------------

---------------functions---------------
fit(model, data_pars,  out_pars=None, compute_pars=None,  **kwargs)
get_dataset( data_pars=None,  )
get_pars( choice="test",  **kwargs)
log( n=0, m=1,  *s)
metrics(model,  sess=None, data_pars=None, out_pars=None,  )
os_file_path(data_path,   )
os_module_path(  )
os_package_root_path(filepath,  sublevel=0, path_add="",  )
predict(model, sess,  data_pars=None, out_pars=None, compute_pars=None, get_hidden_state=False, init_value=None,  )
reset_model(  )
test( data_path="dataset/GOOG-year.csv", out_path="", reset=True,  )
test2( data_path="dataset/GOOG-year.csv",  )

